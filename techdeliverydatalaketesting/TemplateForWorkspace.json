{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"workspaceName": {
			"type": "string",
			"metadata": "Workspace name",
			"defaultValue": "techdeliverydatalaketesting"
		},
		"AXDBConnectionString_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'AXDBConnectionString'"
		},
		"FnO_TechDeliverySynapse_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'FnO_TechDeliverySynapse'"
		},
		"Target_Database_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'Target_Database'",
			"defaultValue": "Integrated Security=False;Encrypt=True;Connection Timeout=30;Data Source=@{linkedService().DbServer};Initial Catalog=@{linkedService().DbName}"
		},
		"d365techdelivery_CustTable_password": {
			"type": "secureString",
			"metadata": "Secure string for 'password' of 'd365techdelivery_CustTable'"
		},
		"techdeliverydatalaketesting-WorkspaceDefaultSqlServer_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'techdeliverydatalaketesting-WorkspaceDefaultSqlServer'",
			"defaultValue": "Integrated Security=False;Encrypt=True;Connection Timeout=30;Data Source=tcp:techdeliverydatalaketesting.sql.azuresynapse.net,1433;Initial Catalog=@{linkedService().DBName}"
		},
		"Source_DataLake_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "@{linkedService().StorageAccount}"
		},
		"d365techdelivery_CustTable_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://d365techdelivery-dev.sandbox.operations.dynamics.com/data"
		},
		"d365techdelivery_CustTable_properties_typeProperties_userName": {
			"type": "string",
			"defaultValue": "greggra@stoneridgesoftware.com"
		},
		"techdeliverydatalaketesting-WorkspaceDefaultStorage_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://techdeliverydatalake.dfs.core.windows.net"
		}
	},
	"variables": {
		"workspaceId": "[concat('Microsoft.Synapse/workspaces/', parameters('workspaceName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('workspaceName'), '/CDMUtil')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Use this template to reads Common Data Model (CDM) metadata generated by Dynamics 365 Finance and Operations Export to Datalake feature, convert and execute SQL DDL statements on the target endpoint. \n\nTarget endpoints and metadata types \n\nSynapse Serverless pool: OpenRowSet Views/External Tables and Views \nSynapse Dedicated pool: Tables and Views \nSQL Server: Tables and Views \n\nRead documentation for details: \nhttps://github.com/microsoft/Dynamics-365-FastTrack-Implementation-Assets/blob/master/Analytics/CDMUtilSolution/readme_cdmutilpipeline.md",
				"activities": [
					{
						"name": "Target_WriteMetadata",
						"description": "Switch to different target endpoints ( Synapse Serverless (Default), Synapse Dedicated pool (SynapseTable) or SQL endpoint = SQLTable)",
						"type": "Switch",
						"dependsOn": [
							{
								"activity": "SQLTarget_CopyMetadata",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "SQLTarget_CopyDependency",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"on": {
								"value": "@pipeline().parameters.DDLType",
								"type": "Expression"
							},
							"cases": [
								{
									"value": "SynapseTable",
									"activities": [
										{
											"name": "CreateSynapseTable",
											"description": "Synapse Dedicated pool endpoint",
											"type": "Script",
											"dependsOn": [],
											"policy": {
												"timeout": "0.01:00:00",
												"retry": 0,
												"retryIntervalInSeconds": 30,
												"secureOutput": false,
												"secureInput": false
											},
											"userProperties": [],
											"linkedServiceName": {
												"referenceName": "Target_Database",
												"type": "LinkedServiceReference"
											},
											"typeProperties": {
												"scripts": [
													{
														"type": "NonQuery",
														"text": {
															"value": "declare @dependency bit = @{if(equals(pipeline().parameters.GetDependency,false),0,1)};\ndeclare @environment nvarchar(100) = '@{pipeline().parameters.Environment}';\ndeclare @Storage nvarchar(1000) = '@{pipeline().parameters.StorageAccount}'\ndeclare @Container nvarchar(1000) = '@{pipeline().parameters.container}'\nDeclare @StorageDS nvarchar(300) = '@{pipeline().parameters.StorageAccount}@{replace(concat(pipeline().parameters.container,'/',pipeline().parameters.Environment), '//','/')}';\n\ndeclare @schema nvarchar(10) = '@{pipeline().parameters.Schema}';\ndeclare @fileFormat nvarchar(100);\ndeclare @ObjectTypes varchar(100) = '@{pipeline().parameters.ObjectTypes}'\ndeclare @TablesPredicate varchar(12) = (select value + '%'  from string_split(@ObjectTypes, ',') where value = 'Tables')\ndeclare @ChangeFeedPredicate varchar(12) = (select value + '%'  from string_split(@ObjectTypes, ',') where value = 'ChangeFeed')\ndeclare @EntitiesPredicate varchar(12) = (select value + '%'  from string_split(@ObjectTypes, ',') where value = 'Entities')\ndeclare @dateTimeFunct nvarchar(50) = 'SYSUTCDATETIME()';\n\nprint('--Metadata prep--');\n\tIF NOT EXISTS (SELECT * FROM sys.objects WHERE object_id = OBJECT_ID(N'[dbo].[_cdmmetadata]') AND type in (N'U'))\n\t\tcreate table _cdmmetadata\n\t\t(\n\t\t\t[definitions] [varchar](max) NULL,\n\t\t\t[FilePath] [varchar](1000) NULL,\n\t\t\t[Environment]   [varchar](1000) NULL,\n\t\t\t[entities] varchar(max) Null,\n\t\t\t[EntityName] varchar(500) Null,\n\t\t\t[DataPath] varchar(1000) Null,\n\t\t\t[ObjectType] varchar(1000) null,\n\t\t\t[Resolved] int Null\n\t\t)\n\t\tWITH(HEAP)\n\n\n\tIF NOT EXISTS (SELECT * FROM sys.objects WHERE object_id = OBJECT_ID(N'[dbo].[_sqlmetadata]') AND type in (N'U'))\n\t\tCREATE TABLE [dbo]._sqlmetadata\n\t\t(\n\t\t\t[Environment] [varchar](1000) NULL,FilePath varchar(1000), [ObjectType] varchar(1000) null,\n\t\t\tEntityName varchar(400), DataPath VARCHAR(500), ViewDef varchar(max), ColumnList varchar(max), NameList varchar(max), DataTypeList varchar(max), \n\t\t\tDataLengthList varchar(max),KeyColumns varchar(1000)\n\t\t)\n\t\tWITH(HEAP);\n\n\tIF NOT EXISTS (SELECT * FROM sys.objects WHERE object_id = OBJECT_ID(N'[dbo].[_controltableforcopy]') AND type in (N'U'))\n\t\tCREATE TABLE [dbo].[_controltableforcopy]\n\t\t(\n\t\t\t[TableSchema] [varchar](20) NULL,\n\t\t\t[TableName] [varchar](255) NULL,\n\t\t\t[StorageAccount] varchar(1000) Null,\n\t\t\t[Container] varchar(1000) Null,\n\t\t\t[Environment] varchar(1000) Null,\n\t\t\t[DataPath] varchar(1000) Null,\n\t\t\t[DataLocation] [varchar](1000) NULL,\n\t\t\t[FileFormat]   [varchar](100) NULL,\n\t\t\t[LastCopyDateTime] [datetime2](7) NULL,\n\t\t\t[LastCopyMarker] [varchar](255) NULL,\n\t\t\t[LastCopyStatus] [int] NULL,\n\t\t\t[LastCopyDuration] [int] NULL,\n\t\t\t[Incremental] [int] DEFAULT 1,\n\t\t\t[RefreshInterval] [int] DEFAULT 60,\n\t\t\t[Active] int DEFAULT 1\n\t\t)\n\t\tWITH (HEAP)\n\n\tIF NOT EXISTS (SELECT * FROM sys.objects WHERE object_id = OBJECT_ID(N'[dbo].[_viewreplacement]') AND type in (N'U'))\n\t\tCREATE Table  [dbo].[_viewreplacement] \n\t\t(\n\t\t\tViewName varchar(100),\n\t\t\tS1 varchar(max),\n\t\t\tR1 varchar(max),\n\t\t\tS2 varchar(max),\n\t\t\tR2 varchar(max),\n\t\t\tS3 varchar(max),\n\t\t\tR3 varchar(max),\n\t\t\tS4 varchar(max),\n\t\t\tR4 varchar(max),\n\t\t\tS5 varchar(max),\n\t\t\tR5 varchar(max)\n\t\t)\n\t\tWITH(HEAP);\n\n\tIF NOT EXISTS (SELECT * FROM sys.objects WHERE object_id = OBJECT_ID(N'[dbo].[_dependency]') AND type in (N'U'))\n\t\tCreate Table _dependency \n\t\t(\n\t\t\tParentEntity varchar(200) null,\n\t\t\tObjectType varchar(200) null ,\n\t\t\tEntityName varchar(200) null,\n\t\t\tColumnList varchar(max) Null,\t\n\t\t\tViewDef varchar(max) null,\n\t\t\tKeyColumns varchar(300) null)\n\t\tWITH(HEAP)\n\n\tIF (@dependency = 1)\n\tBEGIN\n\n\tCOPY INTO [dbo].__dependencies \n\t\tFROM '@{pipeline().parameters.StorageAccount}@{replace(concat(pipeline().parameters.container,'/',pipeline().parameters.Environment), '//','/')}/dependencies.parquet'\n\t\tWITH \n\t\t(\n\t\t\tFILE_TYPE = 'Parquet',\n\t\t\tCREDENTIAL = (IDENTITY = 'Managed Identity'),\n\t\t\tAUTO_CREATE_TABLE = 'ON'\n\t\t)\n\n\tinsert into _dependency (ParentEntity, ObjectType, EntityName, ViewDef)\n\tSELECT \t\n\t\t\tEntityName as ParentEntity,\n\t\t\t'Entities' as ObjectType,\n\t\t\tObjectName as EntityName,\n\t\t\t[definition] as ViewDef\n\t\tFROM __dependencies\n\t\tCross apply openjson(DependentObjects) WITH (\n\t\t\tobjectName nvarchar(200),  \n\t\t\ttype NVARCHAR(50), \n\t\t\t[definition] nvarchar(max))\n\t\twhere type = 'view'\n\t\tand EntityName != ObjectName;\n\t\n\tinsert into _dependency (ParentEntity, ObjectType, EntityName, ColumnList, KeyColumns)\n\tSELECT \t\n\t\t\tEntityName,\n\t\t\t'Tables' as ObjectType,\n\t\t\tTableName,\n\t\t\tSTRING_AGG(CONVERT(NVARCHAR(max), + '[' + COLUMN_NAME + '] ' +  \n\t\t\t\tcase    \n\t\t\t\t\twhen DATA_TYPE = 'nvarchar' and CHARACTER_MAXIMUM_LENGTH < 0  then 'nvarchar(max)'   \n\t\t\t\t\twhen DATA_TYPE = 'nvarchar' then 'nvarchar(' + convert(nvarchar(10), CHARACTER_MAXIMUM_LENGTH) + ')'\n\t\t\t\t\twhen DATA_TYPE = 'timestamp' then 'varbinary(100)'\n\t\t\t\t\twhen DATA_TYPE = 'decimal' then 'decimal(32,16)'  \n\t\t\t\t\telse DATA_TYPE\n\t\t\t\tend) , ','),\n\t\t\tstring_agg(convert(nvarchar(max), case when [Key] is not null then COLUMN_NAME else null end), ',') WITHIN GROUP (ORDER BY [Key] ASC)  as KeyColumn\n\t\t\tFROM __dependencies\n\t\tCross apply openjson(DependentTables) \n\t\tWITH (TableName nvarchar(200),  Attributes NVARCHAR(MAX) '$.Attributes' AS JSON)\n\t\tCROSS APPLY OPENJSON(Attributes,'$')\n\t\tWITH \n\t\t(\n\t\t\tCOLUMN_NAME NVARCHAR(300) '$.COLUMN_NAME',DATA_TYPE NVARCHAR(300) '$.DATA_TYPE',CHARACTER_MAXIMUM_LENGTH NVARCHAR(300) '$.CHARACTER_MAXIMUM_LENGTH', [KEY] int\n\t\t)\n\t\tgroup by EntityName, TableName;\n\n\tdrop table __dependencies\n\n\tEND;\n\n\t-- copy data to _viewreplacement\n\n\tBEGIN TRY;\n\t\n\tCreate Table #ReplaceViewSyntax\n\t(\n\t\tjsonText nvarchar(max)\n\t) \t\n\tWITH(HEAP);\n\n\ttruncate table [dbo].[_viewreplacement];\n\n\tCOPY INTO #ReplaceViewSyntax (jsonText)\n\t\tFROM '@{pipeline().parameters.StorageAccount}@{replace(concat(pipeline().parameters.container,'/',pipeline().parameters.Environment), '//','/')}/ReplaceViewSyntax.json'\n\tWITH (\n\t\t\tFILE_TYPE = 'CSV'\n\t\t\t,fieldterminator ='0x0b'\n\t\t\t,fieldquote = '0x0b'\n\t\t\t,rowterminator = '0x0c'  \n\t\t\t,CREDENTIAL=(IDENTITY= 'Managed Identity')\n\t\t);\n\t\n\tWITH  \n\tViewReplacementDefinition\n\tAS\n\t(\n\t\tSELECT   \n    \t\t\t ROW_NUMBER() OVER ( PARTITION BY  [ViewName] ORDER BY (SELECT NULL)) as [ReplacementIndex]\n\t\t\t\t ,[SearchText]\n\t\t\t\t ,[ReplacementText]\n\t\t\t\t ,[ViewName]\n\t\t\t\t from #ReplaceViewSyntax \t\t\t\n\t\t\t\tCROSS APPLY OPENJSON([jsonText])   \n\t\t\t\tWITH (    [SearchText] NVARCHAR(MAX) '$.Key'\n    \t\t\t\t\t, [ReplacementText] NVARCHAR(MAX) '$.Value' \n    \t\t\t\t\t, [ViewName] NVARCHAR(110) '$.ViewName' \n\t\t\t\t)\n\t)\n\n\tInsert Into  [dbo].[_viewreplacement] \n\tSELECT S.ViewName,\n\t\tisnull(S1, '') AS S1,\n\t\tisnull(R1, '') AS R1,\n\t\tisnull(S2, '') AS S2,\n\t\tisnull(R2, '') AS R2,\n\t\tisnull(S3, '') AS S3,\n\t\tisnull(R3, '') AS R3,\n\t\tisNull(S4, '') AS S4,\n\t\tisNull(R4, '') AS R4,\n\t\tisnull(S5, '') AS S5,\n\t\tisnull(R5, '') AS R5\n\tFROM (\n\t\tSELECT ViewName,\n\t\t\t[1] AS S1,\n\t\t\t[2] AS S2,\n\t\t\t[3] AS S3,\n\t\t\t[4] AS S4,\n\t\t\t[5] AS S5\n\t\tFROM (\n\t\t\tSELECT ViewName,\n\t\t\t\tSearchText,\n\t\t\t\t[ReplacementIndex]\n\t\t\tFROM ViewReplacementDefinition\n\t\t\t) p\n\t\tPIVOT(MIN([SearchText]) FOR [ReplacementIndex] IN (\n\t\t\t\t\t[1],\n\t\t\t\t\t[2],\n\t\t\t\t\t[3],\n\t\t\t\t\t[4],\n\t\t\t\t\t[5]\n\t\t\t\t\t)) AS ReplaceOldStringPivot\n\t\t) S\n\tJOIN (\n\t\tSELECT ViewName,\n\t\t\t[1] AS R1,\n\t\t\t[2] AS R2,\n\t\t\t[3] AS R3,\n\t\t\t[4] AS R4,\n\t\t\t[5] AS R5\n\t\tFROM (\n\t\t\tSELECT ViewName,\n\t\t\t\t[ReplacementText],\n\t\t\t\t[ReplacementIndex]\n\t\t\tFROM ViewReplacementDefinition\n\t\t\t) p\n\t\tPIVOT(MIN([ReplacementText]) FOR [ReplacementIndex] IN (\n\t\t\t\t\t[1],\n\t\t\t\t\t[2],\n\t\t\t\t\t[3],\n\t\t\t\t\t[4],\n\t\t\t\t\t[5]\n\t\t\t\t\t)) AS ReplaceNewStringPivot\n\t\t) R\n\t\tON S.ViewName = R.ViewName\n\n\tDrop Table #ReplaceViewSyntax;\n\n\tEND TRY\n\tBEGIN CATCH\n\t\tprint('ReplaceViewSyntax.json error')\n\tEND CATCH;\n\n\t\n\t\ndelete from dbo._cdmmetadata where Environment = @environment; \n\nCopy Into dbo._cdmmetadata (definitions, FilePath,Environment,entities, EntityName)\n\tFROM '@{pipeline().parameters.StorageAccount}@{replace(concat(pipeline().parameters.container,'/',pipeline().parameters.Environment), '//','/')}/metadata.parquet'\nWITH (\n    FILE_TYPE = 'Parquet',\n    CREDENTIAL = (IDENTITY = 'Managed Identity'),\n\tAUTO_CREATE_TABLE = 'ON'\n\t)\n\t\t\nupdate _cdmmetadata\nset EntityName = case when FilePath like '%ChangeFeed/%' then '_cdc_' + EntityName else  EntityName end ,\nDataPath = replace(replace(replace([FilePath], '/resolved/', '/'), '.cdm.json', ''), '-resolved', '') + '/*.csv',\nResolved = case when FilePath  like '%resolved%' then 1 else 0 end,\nObjectType = SUBSTRING (FilePath,0,CHARINDEX('/',FilePath)) \nwhere  Environment = @environment\n\ndelete from _cdmmetadata\nwhere FilePath not in (\nselect x.[FilePath]\nfrom _cdmmetadata x\ninner join \n(\n\tselect max (resolved) as resolved ,  DataPath\n\tfrom _cdmmetadata \n\tgroup by DataPath\n) y\non x.resolved = y.resolved and x.dataPath = y.datapath\nwhere [definitions] is not null)\n\t\n\tdelete from [dbo]._sqlmetadata where Environment = @environment; \n\n\tinsert into [dbo]._sqlmetadata (Environment, EntityName, ObjectType, ColumnList, NameList, DataPath, ViewDef)\n\tselect distinct\n\t@environment,\n\tfinal.EntityName,\n\tfinal.ObjectType,\t\n\tfinal.ColumnListP1,\n\tfinal.ColumnListP2,\n\tfinal.DataPath,\n\tfinal.ViewDef\n\tfrom \n\t\t(\n\t\t\tselect \n\t\t\t\tx.EntityName,\n\t\t\t\tx.DataPath,\n\t\t\t\treplace(replace(replace(x.ViewDef ,isNull(vr.S1, ''), isNull(vr.R1,'')), isnull(vr.S2, ''), isnull(vr.R2,'')),isnull(vr.S3, ''), isnull(vr.R3, '')) as ViewDef,\n\t\t\t\tx.ObjectType,\n\t\t\t\tcase \n\t\t\t\t\twhen x.ObjectType = 'ChangeFeed' and  x.ViewDef is not null then 0 \n\t\t\t\t\telse 1 \n\t\t\t\tend as IsValid,\n\t\t\t\tSTRING_AGG(CONVERT(NVARCHAR(max), + '[' + name + '] ' +  \n\t\t\t\tcase    \n\t\t\t\t\twhen x.dataType = 'nvarchar' and x.maxLength < 0  then 'nvarchar(max)'   \n\t\t\t\t\twhen x.datatype = 'nvarchar' then 'nvarchar(' + convert(nvarchar(10), x.maxLength) + ')'\n\t\t\t\t\twhen x.datatype = 'varbinary' then 'varbinary(' + convert(nvarchar(10), x.maxLength) + ')'\n\t\t\t\t\twhen x.datatype = 'decimal' then 'decimal(32,16)'  \n\t\t\t\t\telse x.datatype\n\t\t\t\tend) , ',') WITHIN GROUP (ORDER BY ordinal ASC) as ColumnListP1,\n\t\t\t\tSTRING_AGG(CONVERT(NVARCHAR(max), + '[' + name + '] ' +  \n\t\t\t\tcase    \n\t\t\t\t\twhen x.dataType = 'nvarchar' and x.maxLength < 0  then 'default '''   \n\t\t\t\t    else ''\n\t\t\t\tend) , ',') WITHIN GROUP (ORDER BY ordinal ASC) as ColumnListP2\n\t\t\tfrom \n\t\t\t( \n\t\t\t\tselect \n\t\t\t\t\tFilePath,\n\t\t\t\t\tEntityName,\n\t\t\t\t\tObjectType,\n\t\t\t\t\tDataPath,   \n\t\t\t\t\t(Select ISNULL(viewDefinition, viewDefinition1)\n\t\t\t\t\t\tFrom  OPENJSON(definitions, '$[0].exhibitsTraits') \n\t\t\t\t\t\tWITH (\n\t\t\t\t\t\ttraitReference NVARCHAR(100) '$.traitReference',\n\t\t\t\t\t\tviewDefinition nvarchar(max) '$.arguments[0].value',\n\t\t\t\t\t\tviewDefinition1 nvarchar(max) '$.arguments[0]'\n\t\t\t\t\t\t)where traitReference = 'has.sqlViewDefinition') as ViewDef,\n\t\t\t\t\tname,   \n\t\t\t\t\tcase      \n\t\t\t\t\t\twhen datatype ='guid' then 'UNIQUEIDENTIFIER'  \n\t\t\t\t\t\twhen lower(name) ='_sysrowid' then 'bigint'\n\t\t\t\t\t\twhen datatype = 'string' and enum = 'is.constrainedList.wellKnown' then 'int'\n\t\t\t\t\t\twhen datatype = 'string' then 'nvarchar'\n\t\t\t\t\t\twhen datatype = 'int32' then 'int'   \n\t\t\t\t\t\twhen datatype = 'int64' then 'bigInt'    \n\t\t\t\t\t\twhen datatype = 'boolean' then 'bit'   \n\t\t\t\t\t\twhen datatype = 'double' then 'real' \n\t\t\t\t\t\twhen datatype = 'Time' then 'int'  \n\t\t\t\t\t\twhen datatype = 'Binary' then 'varbinary'  \n\t\t\t\t\t\telse datatype \n\t\t\t\t\tend as dataType,    \n\t\t\t\t\tcase \n\t\t\t\t\t\twhen datatype = 'string' and  maxLength > 4000 then -1\n\t\t\t\t\t\twhen datatype = 'string' and lower(name) ='lsn' then 60\n\t\t\t\t\t\twhen datatype = 'string' and lower(name) = 'start_lsn' then 60\n\t\t\t\t\t\twhen datatype = 'string' and lower(name) = 'seq_val' then 60\n\t\t\t\t\t\twhen datatype = 'string' and lower(name) = 'dml_action' then 15\n\t\t\t\t\t\twhen datatype = 'string' and lower(name) = 'update_mask' then 200\n\t\t\t\t\t\twhen datatype = 'string' and lower(name) = 'createdby' then 20\n\t\t\t\t\t\twhen datatype = 'string' and lower(name) = 'modifiedby' then 20\n\t\t\t\t\t\twhen datatype = 'string'  and maxLength is null then 1000\n\t\t\t\t\t\twhen datatype = 'Binary'  and maxLength is null then 100\n\t\t\t\t\t\twhen datatype = 'string'  then maxLength \n\t\t\t\t\tend as maxLength,\n\t\t\t\t\tenum,\n\t\t\t\t\t0 as ordinal\n\t\t\t\tfrom _cdmmetadata \n\t\t\t\tcross apply OPENJSON(definitions, '$[0].hasAttributes')  \n\t\t\t\t\tWITH (name nvarchar(200),  datatype NVARCHAR(50) '$.dataFormat' , maxLength int '$.maximumLength' \n\t\t\t\t\t,scale int '$.traits[0].arguments[1].value', enum nvarchar(max) '$.appliedTraits[3].traitReference')\n\t\t\t\t\twhere environment =   'finance.sandbox.operations.dynamics.com'\n\t\t) x\n\t\tleft outer join _viewreplacement vr on vr.ViewName = x.EntityName\n\t\tgroup by x.EntityName,x.objectType, x.DataPath,x.ViewDef, x.FilePath, S1, R1, S2, R2, S3, R3\n\t) final\n\twhere final.IsValid = 1\n\t\n\tinsert into [dbo]._sqlmetadata (Environment, EntityName, ObjectType, ColumnList, ViewDef)\n\tSELECT \t\n\t\t@environment,\n\t\tEntityName,\n\t\tObjectType,\n\t\tColumnList,\n\t\tViewDef\n\tfrom _dependency \n\twhere EntityName is not null\n\tand EntityName not in (select EntityName from _sqlmetadata where Environment = @environment );\n\n\tupdate T\n\tset T.KeyColumns = D.KeyColumns\n\tfrom [dbo]._sqlmetadata as T\n\tinner join _dependency D on T.ObjectType = D.ObjectType and T.EntityName = D.EntityName\n\twhere T.ObjectType = 'Tables' and T.Environment =  @environment;\n\nINSERT INTO [dbo].[_controltableforcopy](TableSchema,TableName, StorageAccount, Container, Environment , DataPath, DataLocation,FileFormat)\n\tSELECT distinct @schema, EntityName, @Storage, @Container, @Environment, dataPath, @StorageDS + '/' + dataPath, 'CSV' \n\tFROM _sqlmetadata\n\twhere DataPath like @TablesPredicate\n\tand Environment = @Environment\n\tand DataPath is not null\n\tand NOT EXISTS (SELECT DISTINCT TableName FROM [dbo].[_ControlTableForCopy] WHERE TableSchema = @schema and TableName = EntityName)\n\nDeclare @CreateTableDDLTemplate nvarchar(max) = 'If (OBJECT_ID(''{0}.{1}'') is  NULL) create TABLE {0}.{1} ({2}) WITH (DISTRIBUTION = HASH(RecId))'\n\n\ndeclare @ddl nvarchar(max);\n\nset @ddl= (\n\tselect \n\tstring_agg(convert(nvarchar(max), objectDDL ), ';') WITHIN GROUP (ORDER BY ObjectType DESC)\n\tfrom (\n\t\tselect \n\t\t\tObjectType,\n\t\t\tCase \n\t\t\t\twhen ObjectType = 'Entities' then \n\t\t\t\t\t'If (OBJECT_ID(''dbo.'+ EntityName + ''') is  NULL) ' + 'begin try execute sp_executesql N''' +\t\n\t\t\t\t\treplace(replace(replace(replace(replace(replace(replace(ViewDef\n\t\t\t\t\t\t\t\t\t\t, '[dbo].GetValidFromInContextInfo()', @dateTimeFunct)\n\t\t\t\t\t\t\t\t\t\t, '[dbo].GetValidToInContextInfo()', @dateTimeFunct)\n\t\t\t\t\t\t\t\t\t\t, 'dbo.GetValidFromInContextInfo()', @dateTimeFunct)\n\t\t\t\t\t\t\t\t\t\t, 'dbo.GetValidToInContextInfo()', @dateTimeFunct)\n\t\t\t\t\t\t\t\t\t\t, 'GetValidFromInContextInfo()', @dateTimeFunct)\n\t\t\t\t\t\t\t\t\t\t, 'GetValidToInContextInfo()', @dateTimeFunct)\n\t\t\t\t\t\t\t\t\t\t, '''', '''''')\n\t\t\t\t\t+ '''' + ' End Try Begin catch print ERROR_PROCEDURE() + '':'' print ERROR_MESSAGE() end catch'\n\t\t\t\tWhen (ObjectType = 'Tables' or ObjectType = 'ChangeFeed') then \n\t\t\t\t\t'begin try; execute sp_executesql N''' +\n\t\t\t\t\treplace(\n\t\t\t\t\treplace(replace(replace(@CreateTableDDLTemplate, '{0}', @schema), \n\t\t\t\t\t\t\t\t'{1}', EntityName), \n\t\t\t\t\t\t\t\t'{2}', ColumnList),\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t'''', '''''')\n\t\t\t\t\t+ '''' + ' End Try Begin catch print ERROR_PROCEDURE() + '':'' print ERROR_MESSAGE() end catch'\n\t\tEND as ObjectDDL\n\t\tfrom _sqlmetadata\n\t\twhere ObjectType in (select value from string_split(@ObjectTypes, ','))\n\t) ddl\n)\nbegin try \n--select @ddl\nexecute sp_executesql @ddl\nend try\nbegin catch\n   SELECT  \n            @ddl  as DDL\n\t\t\t,ERROR_NUMBER() AS ErrorNumber  \n            ,ERROR_SEVERITY() AS ErrorSeverity  \n            ,ERROR_STATE() AS ErrorState  \n            ,ERROR_PROCEDURE() AS ErrorProcedure  \n            ,ERROR_MESSAGE() AS ErrorMessage;  \nend catch\n\ndeclare @CreateIndexDDL nvarchar(max)= \n(\n\tselect \n\tstring_agg(convert(nvarchar(max),DDL), ';') \n\tfrom \n\t(\n\t\tSelect \n\t\treplace(replace(replace('if not exists (select * from sys.indexes  where object_id=object_id(''{1}'') and name=''{2}'') create index {2} on {1} ({3})'\n\t\t\t\t\t,'{1}', C.TableName)\n\t\t\t\t\t,'{2}', C.TableName + '_NK_IDX')\n\t\t\t\t\t,'{3}', K.KeyColumns) as DDL\n\t\tFrom _ControlTableForCopy C\n\t\tjoin INFORMATION_SCHEMA.TABLES  T \n\t\ton C.TableSchema = T.TABLE_SCHEMA and C.TableName = T.TABLE_NAME and T.TABLE_TYPE = 'BASE TABLE'\n\t\tJoin _sqlmetadata as K\n\t\ton T.TABLE_NAME = K.EntityName and C.Environment = K.Environment and K.KeyColumns != 'RECID'\n\t) X\n\t);\n--select @CreateIndexDDL\nexecute sp_executesql @CreateIndexDDL;\n",
															"type": "Expression"
														}
													}
												],
												"logSettings": {
													"logDestination": "ActivityOutput"
												}
											}
										}
									]
								},
								{
									"value": "SQLTable",
									"activities": [
										{
											"name": "CreateSQLTable",
											"description": "SQL Server endpoint",
											"type": "Script",
											"dependsOn": [],
											"policy": {
												"timeout": "7.00:00:00",
												"retry": 0,
												"retryIntervalInSeconds": 30,
												"secureOutput": false,
												"secureInput": false
											},
											"userProperties": [],
											"linkedServiceName": {
												"referenceName": "Target_Database",
												"type": "LinkedServiceReference"
											},
											"typeProperties": {
												"scripts": [
													{
														"type": "NonQuery",
														"text": {
															"value": "declare @environment nvarchar(100) = '@{pipeline().parameters.Environment}';\nDeclare @entity nvarchar(200);\nDeclare @location nvarchar(1000);\nDeclare @Storage nvarchar(1000) = '@{pipeline().parameters.StorageAccount}'\ndeclare @Container nvarchar(1000) = '@{pipeline().parameters.container}'\nDeclare @StorageDS nvarchar(300) = '@{pipeline().parameters.StorageAccount}@{replace(concat(pipeline().parameters.container,'/',pipeline().parameters.Environment), '//','/')}';\n\ndeclare @schema nvarchar(10) = '@{pipeline().parameters.Schema}';\ndeclare @fileFormat nvarchar(100);\ndeclare @ObjectTypes varchar(100) = '@{pipeline().parameters.ObjectTypes}'\ndeclare @TablesPredicate varchar(12) = (select value + '%'  from string_split(@ObjectTypes, ',') where value = 'Tables')\ndeclare @ChangeFeedPredicate varchar(12) = (select value + '%'  from string_split(@ObjectTypes, ',') where value = 'ChangeFeed')\ndeclare @EntitiesPredicate varchar(12) = (select value + '%'  from string_split(@ObjectTypes, ',') where value = 'Entities')\n\nprint('--Metadata prep--');\ndeclare @entities nvarchar(max); \n\nIF NOT EXISTS (SELECT * FROM sys.objects WHERE object_id = OBJECT_ID(N'[dbo].[_sqlmetadata]') AND type in (N'U'))\n\tCREATE TABLE [dbo]._sqlmetadata\n\t(\n\t\tFilePath varchar(1000), EntityName varchar(400), DataPath VARCHAR(500), ViewDef varchar(max), ColumnList varchar(max), NameList varchar(max), DataTypeList varchar(max), DataLengthList varchar(max)\n\t)\n\nIF NOT EXISTS (SELECT * FROM sys.objects WHERE object_id = OBJECT_ID(N'[dbo].[_ControlTableForCopy]') AND type in (N'U'))\n\tCREATE TABLE [dbo].[_ControlTableForCopy]\n\t(\n\t\t[TableSchema] [varchar](20) NULL,\n\t\t[TableName] [varchar](255) NULL,\n\t\t[StorageAccount] varchar(1000) Null,\n\t\t[Container] varchar(1000) Null,\n\t\t[Environment] varchar(1000) Null,\n\t\t[DataPath] varchar(1000) Null,\n\t\t[DataLocation] [varchar](1000) NULL,\n\t\t[FileFormat]   [varchar](100) NULL,\n\t\t[LastCopyDateTime] [datetime2](7) NULL,\n\t\t[LastCopyMarker] [varchar](255) NULL,\n\t\t[LastCopyStatus] [int] NULL,\n\t\t[LastCopyDuration] [int] NULL,\n\t\t[Incremental] [int] DEFAULT 1,\n\t\t[RefreshInterval] [int] DEFAULT 60,\n\t\t[Active] int DEFAULT 0\n\t)\n\nIF NOT EXISTS (SELECT * FROM sys.objects WHERE object_id = OBJECT_ID(N'[dbo].[_dependencies]') AND type in (N'U'))    \n\tcreate table _dependencies\n\t(\n\t\t[EntityName] varchar(500) not null,\n\t\t[DependentTables] varchar(max) Null,\n\t\t[DependentObjects] varchar(max) Null,\n\t\t[MemoFields] varchar(max) Null\n\t)\n\ndeclare @createOrAlterView nvarchar(max) =\n'Create or ALTER   function [dbo].[prepDefinitionScript](@viewDef nvarchar(max), @inputmap varchar(1000))\nreturns nvarchar(max)\nas \nbegin\n\t\n\tset @viewDef = ''execute sp_executesql N'''''' + replace(replace(replace(@viewDef, '''''''', ''''''''''''), ''Create Function'', ''Create OR Alter Function''), ''Create View'', ''Create or alter View'') + '''''''';\n\n\tdeclare @counter int = 1;\n\tdeclare @rowCount int = (select count(1) from string_split(@inputmap, '',''))\n\t\n\tWHILE (@counter <= @rowCount)\n\tBEGIN\n\t\tdeclare @map nvarchar(200) = (select value from   string_split(@inputmap, '','', 1) where ordinal = @counter)  \n\t\tdeclare @ViewColumnName varchar(100)= (select value from string_split(@map,'':'', 1) where ordinal=1);\n\t\tdeclare @TableColumnName varchar(100)= (select value from string_split(@map,'':'', 1) where ordinal=2);\n\t\tDeclare @From varchar(100) = replace(replace(''%T[0-9].{0} AS {1},%'', ''{0}'', @TableColumnName), ''{1}'', @ViewColumnName)\n\t\tdeclare @To   varchar(100) = replace(''AS {1},'', ''{1}'', @ViewColumnName)\n\t\tdeclare @Replace varchar(100) = replace(''Null as {1},'', ''{1}'', @ViewColumnName)\n\n\t\tif (PATINDEX(@From, @ViewDef) >0)\n\t\t\tset @ViewDef = (SELECT \n\t\t\treplace(@ViewDef, \n\t\t\tSUBSTRING(@ViewDef, PATINDEX(@From, @ViewDef),  charIndex(@To, @ViewDef) - PATINDEX(@From, @ViewDef) + len(@to))\n\t\t\t, @Replace))\n\n\t\tset @counter = @counter+ 1;\n\tEND \nreturn @ViewDef\nEnd;'\n\nexecute sp_executesql @createOrAlterView;\n\nIF (isNull(@entity,'') = '') \n\tBEGIN;\n\t\t\n\t\tTruncate table [dbo]._sqlmetadata; \n\n\t\tupdate _cdmmetadata\n\t\tset EntityName = case when FilePath like '%ChangeFeed/%' then '_cdc_' + EntityName else  EntityName end ,\n\t\tDataPath = replace(replace(replace([FilePath], '/resolved/', '/'), '.cdm.json', ''), '-resolved', '') + '/*.csv'\n\t\t\n\t\t\n\t\tSet @entities =(select string_agg(convert(nvarchar(max), EntityName),',')  WITHIN GROUP (ORDER BY DataPath desc)\n\t\tFrom ( select distinct EntityName, DataPath from _cdmmetadata\n\t\t\t\twhere  (FilePath like @TablesPredicate\n\t\t\t\tor FilePath like @EntitiesPredicate\n\t\t\t\tor FilePath like @ChangeFeedPredicate)\n\t\t\t ) x\n\t\t );\n\n\tEND;\n\n\t \n\tinsert into [dbo]._sqlmetadata (FilePath,EntityName, DataPath, ViewDef, ColumnList, NameList, DataTypeList, DataLengthList)\n\tselect \n\t\tx.FilePath,\n\t\tx.EntityName,\n\t\tx.DataPath,\n\t\tx.ViewDef,\n\t\tSTRING_AGG(CONVERT(NVARCHAR(max), + '[' + name + '] ' +  case    \n\t\t\twhen x.dataType = 'nvarchar' and x.maxLength < 0 then 'nvarchar(max)'  \n\t\twhen x.datatype = 'nvarchar' then 'nvarchar(' + convert(nvarchar(10), x.maxLength) + ')'\n\t\twhen x.datatype = 'varbinary' then 'varbinary(' + convert(nvarchar(10), x.maxLength) + ')'\n\t\twhen x.datatype = 'decimal' then 'decimal(32,16)'  \n\t\telse x.datatype end) , ','),  \n\t\tSTRING_AGG(CONVERT(NVARCHAR(max), name), ','),\n\t\tSTRING_AGG(CONVERT(NVARCHAR(max), datatype), ','),\n\t\tSTRING_AGG(CONVERT(NVARCHAR(max), isNull(maxLength, 0)), ',')\n\tfrom ( \n\t\t select \n\t\t\tcase when FilePath  like '%resolved%' then 1 else 0 end resolved,\n\t\t\tFilePath,\n\t\t\tcase \n\t\t\t\twhen FilePath like '%ChangeFeed/%'  then '_cdc_'+  JSON_VALUE(definitions, '$[0].entityName')\n\t\t\t\telse JSON_VALUE(definitions, '$[0].entityName')\n\t\t\tend as EntityName,\n\t\t\treplace(replace(replace([FilePath], '/resolved/', '/'), '.cdm.json', ''), '-resolved', '') + '/*.csv' as DataPath,   \n\t\t\t(Select ISNULL(viewDefinition, viewDefinition1) From  OPENJSON(definitions, '$[0].exhibitsTraits') \n\t\t\t\tWITH (\n\t\t\t\t\ttraitReference NVARCHAR(100) '$.traitReference',\n\t\t\t\t\tviewDefinition nvarchar(max) '$.arguments[0].value',\n\t\t\t\t\tviewDefinition1 nvarchar(max) '$.arguments[0]'\n\t\t\t\t\t)\n\t\t\t\twhere traitReference = 'has.sqlViewDefinition') as ViewDef,\n\t\t\t\tname,   \n\t\t\t\tcase      \n\t\t\t\t\twhen datatype ='guid' then 'UNIQUEIDENTIFIER'  \n\t\t\t\t\twhen lower(name) ='_sysrowid' then 'bigint'\n\t\t\t\t\twhen datatype = 'string' and enum = 'is.constrainedList.wellKnown' then 'int'\n\t\t\t\t\twhen datatype = 'string' then 'nvarchar'\n\t\t\t\t\twhen datatype = 'int32' then 'int'   \n\t\t\t\t\twhen datatype = 'int64' then 'bigInt'    \n\t\t\t\t\twhen datatype = 'boolean' then 'bit'   \n\t\t\t\t\twhen datatype = 'double' then 'real' \n\t\t\t\t\twhen datatype = 'DateTime' then 'DateTime'  \n\t\t\t\t\twhen datatype = 'Time' then 'int'  \n\t\t\t\t\twhen datatype = 'Binary' then 'varbinary' \n\t\t\t\t\twhen datatype is null then 'nvarchar'  \n\t\t\t\t\telse datatype \n\t\t\t\tend as dataType,    \n\t\t\t\tcase \n\t\t\t\t\twhen datatype = 'string' and  maxLength > 4000 then -1\n\t\t\t\t\twhen datatype = 'string' and lower(name) ='lsn' then 60\n\t\t\t\t\twhen datatype = 'string' and lower(name) = 'start_lsn' then 60\n\t\t\t\t\twhen datatype = 'string' and lower(name) = 'seq_val' then 60\n\t\t\t\t\twhen datatype = 'string' and lower(name) = 'dml_action' then 15\n\t\t\t\t\twhen datatype = 'string' and lower(name) = 'update_mask' then 200\n\t\t\t\t\twhen datatype = 'string' and lower(name) = 'createdby' then 20\n\t\t\t\t\twhen datatype = 'string' and lower(name) = 'modifiedby' then 20\n\t\t\t\t\twhen datatype = 'string'  and maxLength is null then 1000\n\t\t\t\t\twhen datatype = 'Binary'  and maxLength is null then 100\n\t\t\t\t\twhen datatype = 'string'  then maxLength \n\t\t\t\tend as maxLength,\n\t\t\t\tenum\n\tFrom _cdmmetadata\n\tcross apply OPENJSON(definitions, '$[0].hasAttributes')  \n\tWITH (name nvarchar(200),  datatype NVARCHAR(50) '$.dataFormat' , maxLength int '$.maximumLength' \n\t,scale int '$.traits[0].arguments[1].value', enum nvarchar(max) '$.appliedTraits[3].traitReference')  \n\t) x\n\tinner join \n\t(\n\tselect max (resolved) as version ,  DataPath\n\tfrom \n\t(\n\t\tselect \n\t\t\treplace(replace(replace([FilePath], '/resolved/', '/'), '.cdm.json', ''), '-resolved', '') + '/*.csv' as DataPath,\n\t\t\tcase when FilePath  like '%resolved%' then 1 else 0 end as resolved\n\t\tfrom _cdmmetadata \n\t\twhere definitions is not null\n\t) z\n\tgroup by  z.DataPath\n\t) y\n\ton x.resolved = y.version and x.datapath = y.datapath\n\twhere FilePath not in (select DISTINCT FilePath from [dbo]._sqlmetadata)\n\tgroup by x.EntityName,x.DataPath,x.ViewDef, x.FilePath\n\n\tINSERT INTO [dbo].[_controltableforcopy](TableSchema,TableName, StorageAccount, Container, Environment , DataPath, DataLocation,FileFormat)\n\tSELECT @schema, EntityName, @Storage, @Container, @Environment, dataPath, @StorageDS + '/' + dataPath, 'CSV' FROM _sqlmetadata\n\twhere FilePath like @TablesPredicate\n\tand NOT EXISTS (SELECT DISTINCT TableName FROM [dbo].[_ControlTableForCopy] WHERE TableSchema = @schema and TableName = EntityName)\n\n\tupdate _ControlTableForCopy \n\t\tset Active = 1 \n\t\twhere TableName in (\n\t\tSELECT \n\t\tdistinct   e.entityName\n\t\tFROM [dbo].[_cdmmetadata]\n\t\tcross apply OpenJSON([entities]) \n\t\tWith (entityName nvarchar(300)) e\n\t\twhere entities is not null\n\t\tand FilePath like 'Tables/%')\n\nprint('Entities:' + @entities );\n\nDECLARE @counter int = 1\nDECLARE @recordCount int = (select count(value) from string_split(@entities, ',', 1) )\n\nprint ('EntityCount:' + convert(varchar(10), @recordCount));\nprint ('-- Loop through entities');\n\nDeclare @CreateObjectDDL nvarchar(max);\n\nWHILE @counter <= @recordCount \nBEGIN \n\tdeclare @view int = 0;\n\tdeclare @ViewDefinition nvarchar(max);\n\tdeclare @ColumnList varchar(max)\n\n\tselect top 1 @entity = EntityName, @ViewDefinition = ViewDef, @location = DataPath, @ColumnList = ColumnList\n\t\tFrom _sqlmetadata\n\t\twhere EntityName = (select value from string_split(@entities, ',', 1) where ordinal = @counter);\n\t\n\tPRINT ('Counter:' + convert(varchar(10), @counter));\n\tPRINT ('Entity:' + @entity);\n\tPRINT ('DataLocation:' + @location);\n\t\n\tSET @counter = @counter + 1\n\t\n\tIF (isNull(@ViewDefinition,'') <> '')\n\tBEGIN;  \n\t\tset @view = 1;\n\n\t\tIF EXISTS (Select  1  from  _dependencies where entityName = @entity )\n\t\tBEGIN;\n\t\t\tSET @CreateObjectDDL = \n\t\t\t(\n\t\t\t\tSelect \n\t\t\t\t\tSTRING_AGG(convert(nvarchar(max), \n\t\t\t\t\tx.DDL\n\t\t\t\t\t), ';' + Char(10)) \n\t\t\t\t\tFrom \n\t\t\t\t\t( \n\t\t\t\t\t\tSelect\t\n\t\t\t\t\t\t\t0 as #,\n\t\t\t\t\t\t\t'execute sp_executesql N''create or alter View dbo.' + TableName + ' AS Select ' + STRING_AGG(convert(nvarchar(max), ' Null as ' + COLUMN_NAME), ',') + '''' as DDL\n\t\t\t\t\t\tFrom _dependencies\n\t\t\t\t\t\tcross apply OpenJson(DependentTables) with (TableName varchar(100), Attributes nvarchar(max) as Json) as T\n\t\t\t\t\t\tcross apply OPENJSON(T.Attributes)   with (COLUMN_NAME varchar(100))\n\t\t\t\t\t\twhere TableName not in (Select TABLE_NAME from INFORMATION_SCHEMA.TABLES)\n\t\t\t\t\t\t\tand entityName = @entity\n\t\t\t\t\t\tgroup by TableName\n\t\t\t\t\t\t\n\t\t\t\t\t\tunion \n\t\t\t\t\t\t\n\t\t\t\t\t\tSELECT \n\t\t\t\t\t\t\tROW_NUMBER() Over(ORDER BY (SELECT 100)) as #,\n\t\t\t\t\t\t\tdbo.prepDefinitionScript(definition,MemoFields) as DDL\n\t\t\t\t\t\tFROM [dbo].[_dependencies]\n\t\t\t\t\t\tCross apply openjson(DependentObjects)\n\t\t\t\t\t\tWITH (objectName nvarchar(200),  type NVARCHAR(50) , definition nvarchar(max))\n\t\t\t\t\t\twhere entityName = @entity\n\t\t\t\t\t) x\n\t\t\t);\n\t\tEND;\n\t\tELSE \n\t\t\n\t\tBEGIN;\n\t\t\tSET @CreateObjectDDL = replace(@ViewDefinition, 'Create View', 'Create or Alter View')\n\t\tEND;\n\tEND;\n\n\tIF (@view = 0)\n\tBEGIN;\n\t\tdeclare @CreateTableTemplate nvarchar(max) = 'If (OBJECT_ID(''{0}.{1}'') is  NULL) CREATE Table {0}.{1} ({2},CONSTRAINT PK_{1}_RecIdx PRIMARY KEY CLUSTERED (RecId))'\n\t\tset @CreateObjectDDL = replace(replace(replace(@CreateTableTemplate, '{0}', @schema), '{1}', @entity), '{2}', @ColumnList) ;\n\t\n\tEND;\n\t\t\n\tbegin try\n\t\texecute sp_executesql @CreateObjectDDL;\n\tend try\n\tbegin catch;\n\t\tprint  (ERROR_MESSAGE());  \n\t\tprint (@CreateObjectDDL)\n\tend catch;\n\n\tset @entity = null;\nEND;\n-- Create Index\ndeclare @CreateIndexDDL nvarchar(max)= \n(\n\tselect \n\tstring_agg(convert(nvarchar(max),DDL), ';') \n\tfrom \n\t(\n\t\tSelect \n\t\treplace(replace(replace('if not exists (select * from sysindexes  where id=object_id(''{1}'') and name=''{2}'') create index {2} on {1} ({3})'\n\t\t\t\t\t,'{1}', C.TableName)\n\t\t\t\t\t,'{2}', C.TableName + '_NK_IDX')\n\t\t\t\t\t,'{3}', K.KeyColumn) as DDL\n\t\tFrom _ControlTableForCopy C\n\t\tjoin INFORMATION_SCHEMA.TABLES  T \n\t\ton C.TableSchema = T.TABLE_SCHEMA and C.TableName = T.TABLE_NAME and T.TABLE_TYPE = 'BASE TABLE'\n\t\tJoin \n\t\t(\n\t\t\tselect distinct TableName as TableName,\n\t\t\t\tstring_agg(convert(nvarchar(max),COLUMN_NAME), ',') WITHIN GROUP (ORDER BY [Key] ASC)  as KeyColumn\n\t\t\t\tFrom _dependencies\n\t\t\t\tcross apply OpenJson(DependentTables) with (TableName varchar(100), Attributes nvarchar(max) as Json) as T\n\t\t\t\tcross apply OPENJSON(T.Attributes)   with (COLUMN_NAME varchar(100), [KEY] int)\n\t\t\t\twhere  [KEY] is not Null and COLUMN_NAME != 'RECID'\n\t\t\t\tgroup by EntityName, TableName\n\t\t) K\n\t\ton T.TABLE_NAME = K.TableName\n\t) X\n\t);\nexecute sp_executesql @CreateIndexDDL;",
															"type": "Expression"
														}
													}
												],
												"logSettings": {
													"logDestination": "ActivityOutput"
												}
											}
										}
									]
								}
							],
							"defaultActivities": [
								{
									"name": "CreateSynapse_ViewOrExternalTable",
									"description": "Create View or External Table on Synapse Serverless Database",
									"type": "Script",
									"dependsOn": [
										{
											"activity": "CreateMetadataView",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "Target_Database",
										"type": "LinkedServiceReference"
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "NonQuery",
												"text": {
													"value": "-- Common variables \ndeclare @schema nvarchar(10) = '@{pipeline().parameters.Schema}';\ndeclare @ObjectTypes varchar(100) = '@{pipeline().parameters.ObjectTypes}'\n\n-- Serverless specific variables\ndeclare @datasource nvarchar(200) = '@{pipeline().parameters.Environment}';\ndeclare @parserVersion nvarchar(10) = '@{pipeline().parameters.ParserVersion}';\ndeclare @readOption nvarchar(300) = N'''{\"READ_OPTIONS\":[\"ALLOW_INCONSISTENT_READS\"]}''';\ndeclare @ddlType nvarchar(20) = '@{pipeline().parameters.DDLType}';\ndeclare @dateTimeFunct nvarchar(50) = 'SYSUTCDATETIME()';\ndeclare @fileFormat nvarchar(100);\t\n\nIF (@parserVersion = '2.0')\n\tSET @fileFormat = '_CSV_P2';\nELSE \n\tSET @fileFormat = '_CSV_P1';\n\ndeclare @CreateExternalTableDDL nvarchar(max) = 'If (OBJECT_ID(''{0}.{1}'') IS NOT  NULL) \tDrop external table  {0}.{1}  \n\t\t\t\tCREATE external Table {0}.{1} ({2}) WITH ( LOCATION = ''{3}'', DATA_SOURCE = [{4}], FILE_FORMAT = [{5}], TABLE_OPTIONS ={6})';\ndeclare @CreateViewDDL nvarchar(max) = 'CREATE OR ALTER VIEW  {0}.{1}  AS SELECT cast(r.filepath(1) as varchar(100)) as [$FileName], * FROM  OPENROWSET( BULK ''{3}'',  FORMAT = ''CSV'', \n\t\t\t\tPARSER_VERSION = ''{4}'', DATA_SOURCE = ''{5}'', ROWSET_OPTIONS ={6}) WITH ({2}) as r';\n\n\ndeclare @ddl nvarchar(max);\n\nset @ddl= (\n\tselect \n\tstring_agg(convert(nvarchar(max), objectDDL ), ';') WITHIN GROUP (ORDER BY ObjectType DESC, Ordinal ASC)\n\tfrom (\n\t\tselect \n\t\t\tObjectType,\n\t\t\tOrdinal,\n\t\t\tCase \n\t\t\t\twhen ObjectType = 'Entities' then \n\t\t\t\t\t'begin try execute sp_executesql N''' +\t\n\t\t\t\t\treplace(replace(replace(replace(replace(replace(replace(replace(ViewDef\n\t\t\t\t\t\t\t\t\t\t, '[dbo].GetValidFromInContextInfo()', @dateTimeFunct)\n\t\t\t\t\t\t\t\t\t\t, '[dbo].GetValidToInContextInfo()', @dateTimeFunct)\n\t\t\t\t\t\t\t\t\t\t, 'dbo.GetValidFromInContextInfo()', @dateTimeFunct)\n\t\t\t\t\t\t\t\t\t\t, 'dbo.GetValidToInContextInfo()', @dateTimeFunct)\n\t\t\t\t\t\t\t\t\t\t, 'GetValidFromInContextInfo()', @dateTimeFunct)\n\t\t\t\t\t\t\t\t\t\t, 'GetValidToInContextInfo()', @dateTimeFunct)\n\t\t\t\t\t\t\t\t\t\t,'Create View', 'Create or alter View')\n\t\t\t\t\t\t\t\t\t\t, '''', '''''')\n\t\t\t\t\t+ '''' + ' End Try Begin catch print ERROR_PROCEDURE() + '':'' print ERROR_MESSAGE() end catch'\n\t\t\t\tWhen (ObjectType = 'Tables' or ObjectType = 'ChangeFeed')  and @ddlType = 'SynapseExternalTable' then \n\t\t\t\t\t'execute sp_executesql N''' +\n\t\t\t\t\treplace(\n\t\t\t\t\treplace(replace(replace(replace(replace(replace(replace(@CreateExternalTableDDL, '{0}', @schema), \n\t\t\t\t\t\t\t\t'{1}', EntityName), \n\t\t\t\t\t\t\t\t'{2}', case when @parserVersion = '1.0' then ColumnListP1 else ColumnListP2 end),\n\t\t\t\t\t\t\t\t'{3}', DataPath),\n\t\t\t\t\t\t\t\t'{4}', @datasource),\n\t\t\t\t\t\t\t\t'{5}', @fileFormat), \n\t\t\t\t\t\t\t\t'{6}', @readOption),\n\t\t\t\t\t'''', '''''')\n\t\t\t\t\t+ ''''\n\t\t\t\tWhen (ObjectType = 'Tables' or ObjectType = 'ChangeFeed')   and @ddlType = 'SynapseView' Then \n\t\t\t\t\t'execute sp_executesql N''' +\n\t\t\t\t\treplace(\n\t\t\t\t\treplace(replace(replace(replace(replace(replace(replace(@CreateViewDDL, \n\t\t\t\t\t\t\t'{0}',@schema),\n\t\t\t\t\t\t\t'{1}', EntityName), \n\t\t\t\t\t\t\t'{2}', case when @parserVersion = '1.0' then ColumnListP1 else ColumnListP2 end), \n\t\t\t\t\t\t\t'{3}', DataPath), \n\t\t\t\t\t\t\t'{4}', @parserVersion), \n\t\t\t\t\t\t\t'{5}', @datasource), \n\t\t\t\t\t\t\t'{6}', @readOption) ,\n\t\t\t\t\t'''', '''''')\n\t\t\t\t\t+ ''''\n\t\tEND as ObjectDDL\n\t\tfrom _sqlmetadata\n\t\twhere ObjectType in (select value from string_split(@ObjectTypes, ','))\n\t) ddl\n)\nbegin try \n--select @ddl\nexecute sp_executesql @ddl\nend try\nbegin catch\n   SELECT  \n            @ddl  as DDL\n\t\t\t,ERROR_NUMBER() AS ErrorNumber  \n            ,ERROR_SEVERITY() AS ErrorSeverity  \n            ,ERROR_STATE() AS ErrorState  \n            ,ERROR_PROCEDURE() AS ErrorProcedure  \n            ,ERROR_MESSAGE() AS ErrorMessage;  \nend catch\n",
													"type": "Expression"
												}
											}
										],
										"logSettings": {
											"logDestination": "ActivityOutput"
										}
									}
								},
								{
									"name": "CreateMetadataView",
									"type": "Script",
									"dependsOn": [],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "Target_Database",
										"type": "LinkedServiceReference"
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "Query",
												"text": {
													"value": "declare @dependency bit = @{if(equals(pipeline().parameters.GetDependency,false),0,1)};\ndeclare @environment nvarchar(100) = '@{pipeline().parameters.Environment}';\nDeclare @StorageDS nvarchar(300) = '@{pipeline().parameters.StorageAccount}@{replace(concat(pipeline().parameters.container,'/',pipeline().parameters.Environment), '//','/')}';\n\nDeclare @CreateCredentials nvarchar(max) =  'IF NOT EXISTS(select * from sys.database_credentials where name = '''+@environment+''')\n    CREATE DATABASE SCOPED CREDENTIAL [' +@environment+'] WITH IDENTITY=''Managed Identity''';\n\nexecute sp_executesql  @CreateCredentials;\n\nDeclare @CreateExternalDataSource nvarchar(max) =  'IF NOT EXISTS(select * from sys.external_data_sources where name = '''+ @environment+''')\n        CREATE EXTERNAL DATA SOURCE [' +@environment+'] WITH (\n            LOCATION = '''+ @StorageDS +''',\n            CREDENTIAL = [' + @environment + '])'\nexecute sp_executesql  @CreateExternalDataSource;\n\nIF NOT EXISTS(select * from sys.external_file_formats  where name = '_CSV_P1')\n    CREATE EXTERNAL FILE FORMAT _CSV_P1\n    WITH (  \n        FORMAT_TYPE = DELIMITEDTEXT,\n        FORMAT_OPTIONS ( FIELD_TERMINATOR = ',', STRING_DELIMITER = '\"', FIRST_ROW = 1, USE_TYPE_DEFAULT = true)\n    );\n\nIF NOT EXISTS(select * from sys.external_file_formats  where name = '_CSV_P2')\n    CREATE EXTERNAL FILE FORMAT _CSV_P2\n    WITH (  \n        FORMAT_TYPE = DELIMITEDTEXT,\n        FORMAT_OPTIONS ( FIELD_TERMINATOR = ',', STRING_DELIMITER = '\"', FIRST_ROW = 1, PARSER_VERSION = '2.0' )\n\t\t);\n\nIF NOT EXISTS(select * from sys.external_file_formats  where name = '_parquet')\n    CREATE EXTERNAL FILE FORMAT _parquet\n    WITH (  \n        FORMAT_TYPE = Parquet\n\t\t);\n\nEXEC('CREATE OR ALTER  VIEW [dbo].[_cdmmetadata] \nAS\nwith _cdm AS\n( Select \n\t\t[definitions],\n\t\t[FilePath] ,\n\t\t[Environment],\n\t\t[entities], \n\t\treplace(replace(replace([FilePath], ''/resolved/'', ''/''), ''.cdm.json'', ''''), ''-resolved'', '''') + ''/*.csv'' as DataPath,\n\t\tcase when FilePath  like ''%resolved%'' then 1 else 0 end as resolved,\n\t\tcase \n\t\t\twhen FilePath like ''%ChangeFeed/%''  then ''_cdc_''+  JSON_VALUE(definitions, ''$[0].entityName'')\n\t\t\telse JSON_VALUE(definitions, ''$[0].entityName'')\n\t\tend as EntityName\n\tfrom Openrowset ( Bulk ''/metadata.parquet'', Format = ''Parquet'', DATA_SOURCE = ''@{pipeline().parameters.Environment}'')\n \tWITH ( [definitions] [varchar](max),\n\t\t[FilePath] [varchar](1000),\n\t\t[Environment]   [varchar](1000),\n\t\t[entities] varchar(max)\n\n\t) as r\n\twhere definitions is not null\n)\nselect \nROW_NUMBER() OVER (ORDER BY FilePath DESC) as Id,\nx.[definitions],\nx.[FilePath] ,\nx.[Environment],\nx.[entities], \nx.DataPath,\nSUBSTRING (x.DataPath,0,CHARINDEX(''/'',x.DataPath)) as ObjectType,\nx.EntityName,\nx.resolved\n from _cdm x\ninner join \n(\n\tselect max (resolved) as resolved ,  DataPath\n\tfrom _cdm \n\tgroup by DataPath\n) y\non x.resolved = y.resolved and x.dataPath = y.datapath;')\n\n\nIF OBJECT_ID('dbo._dependency') IS NULL\nEXEC('CREATE view  [dbo].[_dependency] as SELECT \n\t\tcast(null as nvarchar(100)) as ParentEntity,\n\t\tcast(null as nvarchar(1000)) as EntityName,\n\t\tcast(null as nvarchar(100)) as ObjectType,\n\t\tcast(null as nvarchar(max)) as ColumnListP1,\n\t\tcast(null as nvarchar(max)) as ColumnListP2,\n\t\tcast(null as nvarchar(4000)) as DataPath,\n\t\tcast(null as nvarchar(max)) as ViewDef,\n\t\tcast(null as nvarchar(max)) as MemoFields')  \n\t\t\nIF (@dependency =1) \nEXEC('CREATE OR ALTER view  [dbo].[_dependency] as\nSELECT \t\n\t\tEntityName as ParentEntity,\n\t\tObjectName as EntityName,\n\t\t''Entities'' as ObjectType,\n\t\t'''' as ColumnListP1,\n\t\t'''' as ColumnListP2,\n\t\t'''' as DataPath,\n\t\t[definition] as ViewDef,\n\t\t[MemoFields]\n\tFROM Openrowset ( Bulk ''/dependencies.parquet'', Format = ''Parquet'', DATA_SOURCE = ''@{pipeline().parameters.Environment}'')\n\tWITH \n\t(\n\t\t[EntityName] varchar(500),\n\t\t[DependentTables] varchar(max) ,\n\t\t[DependentObjects] varchar(max) ,\n\t\t[MemoFields] varchar(max) \n\t) as r\n\tCross apply openjson(DependentObjects)\n\tWITH \n\t(\n\t\tobjectName nvarchar(200),  \n\t\ttype NVARCHAR(50), \n\t\tdefinition nvarchar(max)\n\t)\n\twhere \n\ttype = ''view''\n\tand EntityName != ObjectName\n\tand EntityName in (select distinct entityName from _cdmmetadata)')\n\n\nIF OBJECT_ID('dbo._viewreplacement') IS NULL\nEXEC('CREATE view  [dbo].[_viewreplacement] as SELECT \n\t'''' AS ViewName,\n\t'''' AS S1,\n\t'''' AS R1,\n\t'''' AS S2,\n\t'''' AS R2,\n\t'''' AS S3,\n\t'''' AS R3,\n\t'''' AS S4,\n\t'''' AS R4,\n\t'''' AS S5,\n\t'''' AS R5')  \nbegin try\nExec ('Create or Alter View  _viewreplacement\nAS\nWITH  \nViewReplacementDefinition\nAS\n(\n    SELECT   \n    \t\t ROW_NUMBER() OVER ( PARTITION BY  [ViewName] ORDER BY (SELECT NULL)) as [ReplacementIndex]\n\t\t\t ,[SearchText]\n             ,[ReplacementText]\n             ,[ViewName]\n\t\t\t from Openrowset ( Bulk ''/ReplaceViewSyntax.json'', Format = ''CSV'', DATA_SOURCE = ''@{pipeline().parameters.Environment}''\n\t\t\t\t,fieldterminator =''0x0b'',\n\t\t\t\tfieldquote = ''0x0b'',\n\t\t\t\trowterminator = ''0x0b'' \n\t\t\t\t) with (doc nvarchar(max)) as rows\n\t\t\tCROSS APPLY OPENJSON([doc])            \n\t\t\tWITH (    [SearchText] NVARCHAR(MAX) ''$.Key''\n    \t\t\t\t, [ReplacementText] NVARCHAR(MAX) ''$.Value'' \n    \t\t\t\t, [ViewName] NVARCHAR(110) ''$.ViewName'' \n\t\t\t)\n)\n\nSELECT S.ViewName,\n\tisnull(S1, '''') AS S1,\n\tisnull(R1, '''') AS R1,\n\tisnull(S2, '''') AS S2,\n\tisnull(R2, '''') AS R2,\n\tisnull(S3, '''') AS S3,\n\tisnull(R3, '''') AS R3,\n\tisNull(S4, '''') AS S4,\n\tisNull(R4, '''') AS R4,\n\tisnull(S5, '''') AS S5,\n\tisnull(R5, '''') AS R5\nFROM (\n\tSELECT ViewName,\n\t\t[1] AS S1,\n\t\t[2] AS S2,\n\t\t[3] AS S3,\n\t\t[4] AS S4,\n\t\t[5] AS S5\n\tFROM (\n\t\tSELECT ViewName,\n\t\t\tSearchText,\n\t\t\t[ReplacementIndex]\n\t\tFROM ViewReplacementDefinition\n\t\t) p\n\tPIVOT(MIN([SearchText]) FOR [ReplacementIndex] IN (\n\t\t\t\t[1],\n\t\t\t\t[2],\n\t\t\t\t[3],\n\t\t\t\t[4],\n\t\t\t\t[5]\n\t\t\t\t)) AS ReplaceOldStringPivot\n\t) S\nJOIN (\n\tSELECT ViewName,\n\t\t[1] AS R1,\n\t\t[2] AS R2,\n\t\t[3] AS R3,\n\t\t[4] AS R4,\n\t\t[5] AS R5\n\tFROM (\n\t\tSELECT ViewName,\n\t\t\t[ReplacementText],\n\t\t\t[ReplacementIndex]\n\t\tFROM ViewReplacementDefinition\n\t\t) p\n\tPIVOT(MIN([ReplacementText]) FOR [ReplacementIndex] IN (\n\t\t\t\t[1],\n\t\t\t\t[2],\n\t\t\t\t[3],\n\t\t\t\t[4],\n\t\t\t\t[5]\n\t\t\t\t)) AS ReplaceNewStringPivot\n\t) R\n\tON S.ViewName = R.ViewName')\nend try\nbegin catch\nprint ('view replacement is not created')\nend catch\n\nExec('create or alter view _sqlmetadata \nas \nselect distinct\n\tfinal.EntityName,\n\tfinal.ObjectType,\t\n\tfinal.ColumnListP1,\n\tfinal.ColumnListP2,\n\tfinal.DataPath,\n\tfinal.ViewDef,\n\t1 as Ordinal\n\tfrom \n\t\t(\n\t\t\tselect \n\t\t\t\tx.EntityName,\n\t\t\t\tx.DataPath,\n\t\t\t\t\treplace(replace(replace(x.ViewDef ,isNull(vr.S1, ''''), isNull(vr.R1,'''')), isnull(vr.S2, ''''), isnull(vr.R2,'''')),isnull(vr.S3, ''''), isnull(vr.R3, '''')) as ViewDef,\n\t\t\t\tx.ObjectType,\n\t\t\t\tcase \n\t\t\t\t\twhen x.ObjectType = ''ChangeFeed'' and  x.ViewDef is not null then 0 \n\t\t\t\t\telse 1 \n\t\t\t\tend as IsValid,\n\t\t\t\tSTRING_AGG(CONVERT(NVARCHAR(max), + ''['' + name + ''] '' +  \n\t\t\t\tcase    \n\t\t\t\t\twhen x.dataType = ''nvarchar'' and x.maxLength < 0  then ''nvarchar(max)''   \n\t\t\t\t\twhen x.datatype = ''nvarchar'' then ''nvarchar('' + convert(nvarchar(10), x.maxLength) + '')''\n\t\t\t\t\twhen x.datatype = ''varbinary'' then ''varbinary('' + convert(nvarchar(10), x.maxLength) + '')''\n\t\t\t\t\twhen x.datatype = ''decimal'' then ''decimal(32,16)''  \n\t\t\t\t\telse x.datatype\n\t\t\t\tend) , '','') WITHIN GROUP (ORDER BY ordinal ASC) as ColumnListP1,\n\t\t\t\tSTRING_AGG(CONVERT(NVARCHAR(max), + ''['' + name + ''] '' +  \n\t\t\t\tcase    \n\t\t\t\t\twhen x.dataType = ''nvarchar'' and x.maxLength < 0  then ''nvarchar(8000)''   \n\t\t\t\t\twhen datatype = ''DateTime'' then ''DateTime2''  \n\t\t\t\t\twhen x.datatype = ''nvarchar'' then ''nvarchar('' + convert(nvarchar(10), x.maxLength) + '')''\n\t\t\t\t\twhen x.datatype = ''varbinary'' then ''varbinary('' + convert(nvarchar(10), x.maxLength) + '')''\n\t\t\t\t\twhen x.datatype = ''decimal'' then ''decimal(32,16)''  \n\t\t\t\t\telse x.datatype\n\t\t\t\tend) , '','') WITHIN GROUP (ORDER BY ordinal ASC) as ColumnListP2\n\t\t\tfrom \n\t\t\t( \n\t\t\t\tselect \n\t\t\t\t\tFilePath,\n\t\t\t\t\tEntityName,\n\t\t\t\t\tObjectType,\n\t\t\t\t\tDataPath,   \n\t\t\t\t\t(Select ISNULL(viewDefinition, viewDefinition1)\n\t\t\t\t\t\tFrom  OPENJSON(definitions, ''$[0].exhibitsTraits'') \n\t\t\t\t\t\tWITH (\n\t\t\t\t\t\ttraitReference NVARCHAR(100) ''$.traitReference'',\n\t\t\t\t\t\tviewDefinition nvarchar(max) ''$.arguments[0].value'',\n\t\t\t\t\t\tviewDefinition1 nvarchar(max) ''$.arguments[0]''\n\t\t\t\t\t\t)where traitReference = ''has.sqlViewDefinition'') as ViewDef,\n\t\t\t\t\tname,   \n\t\t\t\t\tcase      \n\t\t\t\t\t\twhen datatype =''guid'' then ''UNIQUEIDENTIFIER''  \n\t\t\t\t\t\twhen lower(name) =''_sysrowid'' then ''bigint''\n\t\t\t\t\t\twhen datatype = ''string'' and enum = ''is.constrainedList.wellKnown'' then ''int''\n\t\t\t\t\t\twhen datatype = ''string'' then ''nvarchar''\n\t\t\t\t\t\twhen datatype = ''int32'' then ''int''   \n\t\t\t\t\t\twhen datatype = ''int64'' then ''bigInt''    \n\t\t\t\t\t\twhen datatype = ''boolean'' then ''bit''   \n\t\t\t\t\t\twhen datatype = ''double'' then ''real'' \n\t\t\t\t\t\twhen datatype = ''Time'' then ''int''  \n\t\t\t\t\t\twhen datatype = ''Binary'' then ''varbinary''  \n\t\t\t\t\t\telse datatype \n\t\t\t\t\tend as dataType,    \n\t\t\t\t\tcase \n\t\t\t\t\t\twhen datatype = ''string'' and  maxLength > 4000 then -1\n\t\t\t\t\t\twhen datatype = ''string'' and lower(name) =''lsn'' then 60\n\t\t\t\t\t\twhen datatype = ''string'' and lower(name) = ''start_lsn'' then 60\n\t\t\t\t\t\twhen datatype = ''string'' and lower(name) = ''seq_val'' then 60\n\t\t\t\t\t\twhen datatype = ''string'' and lower(name) = ''dml_action'' then 15\n\t\t\t\t\t\twhen datatype = ''string'' and lower(name) = ''update_mask'' then 200\n\t\t\t\t\t\twhen datatype = ''string'' and lower(name) = ''createdby'' then 20\n\t\t\t\t\t\twhen datatype = ''string'' and lower(name) = ''modifiedby'' then 20\n\t\t\t\t\t\twhen datatype = ''string''  and maxLength is null then 1000\n\t\t\t\t\t\twhen datatype = ''Binary''  and maxLength is null then 100\n\t\t\t\t\t\twhen datatype = ''string''  then maxLength \n\t\t\t\t\tend as maxLength,\n\t\t\t\t\tenum,\n\t\t\t\t\tordinal\n\t\t\t\tfrom _cdmmetadata \n\t\t\t\tcross apply OPENJSON(definitions, ''$[0].hasAttributes'')  \n\t\t\t\t\tWITH (name nvarchar(200),  datatype NVARCHAR(50) ''$.dataFormat'' , maxLength int ''$.maximumLength'' ,  ordinal int ''$.sql:identity()''\n\t\t\t\t\t,scale int ''$.traits[0].arguments[1].value'', enum nvarchar(max) ''$.appliedTraits[3].traitReference'')  \n\t\t) x\n\t\tleft outer join _viewreplacement vr on vr.ViewName = x.EntityName\n\t\tgroup by x.EntityName,x.objectType, x.DataPath,x.ViewDef, x.FilePath, S1, R1, S2, R2, S3, R3\n\t) final\n\twhere final.IsValid = 1\n\t\n\tunion\n\t\n\tSELECT \t\n\t\tEntityName,\n\t\tObjectType,\n\t\tColumnListP1,\n\t\tColumnListP2,\n\t\tDataPath,\n\t\tViewDef,\n\t\t0 as Ordinal\n\tfrom _dependency\n\twhere EntityName is not null\n\tgroup by viewDef, ObjectType, EntityName, ColumnListP1, ColumnListP2, DataPath;')\n\n\n",
													"type": "Expression"
												}
											}
										]
									}
								}
							]
						}
					},
					{
						"name": "SQLTarget_CopyMetadata",
						"type": "IfCondition",
						"dependsOn": [
							{
								"activity": "CopyMetadata",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@equals(pipeline().parameters.DDLType,'SQLTable')",
								"type": "Expression"
							},
							"ifTrueActivities": [
								{
									"name": "CopyMetadata_SQL",
									"type": "Copy",
									"dependsOn": [],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "ParquetSource",
											"storeSettings": {
												"type": "AzureBlobFSReadSettings",
												"recursive": true,
												"enablePartitionDiscovery": false
											}
										},
										"sink": {
											"type": "AzureSqlSink",
											"preCopyScript": {
												"value": "IF  EXISTS (SELECT * FROM sys.objects WHERE object_id = OBJECT_ID(N'[dbo].[_cdmmetadata]') AND type in (N'U'))\n    Drop Table _cdmmetadata\n    \ncreate table _cdmmetadata\n(\n    [definitions] [varchar](max) NULL,\n    [FilePath] [varchar](1000) NULL,\n    [Environment]   [varchar](1000) NULL,\n    [entities] varchar(max) Null,\n    [EntityName] varchar(500) null,\n    [DataPath] varchar(1000) Null\n)",
												"type": "Expression"
											},
											"writeBehavior": "insert",
											"sqlWriterUseTableLock": false,
											"disableMetricsCollection": false
										},
										"enableStaging": false
									},
									"inputs": [
										{
											"referenceName": "CDMUtil_Metadata_File_Dataset",
											"type": "DatasetReference",
											"parameters": {
												"container": {
													"value": "@pipeline().parameters.container",
													"type": "Expression"
												},
												"folder": {
													"value": "@pipeline().parameters.Environment",
													"type": "Expression"
												},
												"StorageAccount": {
													"value": "@pipeline().parameters.StorageAccount",
													"type": "Expression"
												}
											}
										}
									],
									"outputs": [
										{
											"referenceName": "CDMUtil_SQLTable_Dataset",
											"type": "DatasetReference",
											"parameters": {
												"TableName": {
													"value": "_cdmmetadata",
													"type": "Expression"
												},
												"DbName": {
													"value": "@pipeline().parameters.DbName",
													"type": "Expression"
												},
												"DBServer": {
													"value": "@pipeline().parameters.DbServer",
													"type": "Expression"
												}
											}
										}
									]
								}
							]
						}
					},
					{
						"name": "GetAXDBDependency",
						"description": "If AXDB is provided, copy dependency from AXDB to file .. otherwise check if the dependency file exists",
						"type": "IfCondition",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@pipeline().parameters.GetDependency",
								"type": "Expression"
							},
							"ifFalseActivities": [
								{
									"name": "Dependency",
									"type": "GetMetadata",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataset": {
											"referenceName": "CDMUtil_DependencyFile_Dataset",
											"type": "DatasetReference",
											"parameters": {
												"container": {
													"value": "@pipeline().parameters.container",
													"type": "Expression"
												},
												"folder": {
													"value": "@pipeline().parameters.Environment",
													"type": "Expression"
												},
												"StorageAccount": {
													"value": "@pipeline().parameters.StorageAccount",
													"type": "Expression"
												}
											}
										},
										"fieldList": [
											"exists"
										],
										"storeSettings": {
											"type": "AzureBlobFSReadSettings",
											"recursive": true,
											"enablePartitionDiscovery": false
										}
									}
								}
							],
							"ifTrueActivities": [
								{
									"name": "CopyEntityDependencies",
									"type": "Copy",
									"dependsOn": [],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "AzureSqlSource",
											"sqlReaderQuery": {
												"value": "-----------------------------------------------BEGIN Recursive section ---------------------------------------\ndrop table if exists #myEntitiestree;\nDeclare @entities nvarchar(max)= '@{pipeline().parameters.EntityListForDependency}';\nWith allviews (nodeId, parentNodeId, nodeIdType, rootNode, depth) AS (\n-- 1 Anchor member - represents the list of root nodes considered with a depth of 0\t\n\tselect nv.name as nodeId,\n       CAST(null as NVARCHAR(MAX)) as parentNodeId,\n       CAST('VIEW' as nvarchar(60)) COLLATE DATABASE_DEFAULT as nodeIdType,\n\t   nv.name as rootNode,\n\t   0 as depth\n\tfrom sys.views nv\n\twhere schema_name(nv.schema_id) = 'dbo' \n\tAND nv.name in (select value from string_split(@entities, ','))\n\tunion all\n-- 2 recursive member - represents the iteration path to navigate from a node to its parent\n--increases depth by 1 at each iteration and keeps a trace of the initial root node from the anchor member \n\tselect o.name as nodeId,\n       CAST(p.name as NVARCHAR(Max)) as parentNodeId,\n       o.type_desc COLLATE DATABASE_DEFAULT as nodeIdType,\n\t   allviews.rootNode as rootnode,\n\t   allviews.depth + 1 as depth\n\tfrom sys.sql_expression_dependencies d\n\tjoin sys.objects o\n\t\t\ton o.object_id = d.referenced_id\n\tjoin sys.objects p\n\t\t\ton p.object_id = d.referencing_id\n\tjoin allviews on allviews.nodeId = p.name\n\twhere \n\td.referenced_id is not null and \n-- 3 ending condition\n\tp.type_desc = 'VIEW' and\n\tschema_name(p.schema_id) = 'dbo' and schema_name(o.schema_id) = 'dbo'\n)\n--4 inserts the results in a temporary table for ease of use\nSelect * into #myEntitiestree from allviews ;\n\nSELECT  \n\trootNode as EntityName,\n\t(select \n\t\t\tnodeId as TableName,\n\t\t\t(select C.COLUMN_NAME, DATA_TYPE, CHARACTER_MAXIMUM_LENGTH, NUMERIC_PRECISION, NUMERIC_SCALE, K.ORDINAL_POSITION as [KEY]\n\t\t\t\tfrom INFORMATION_SCHEMA.COLUMNS C\n\t\t\t\tleft join   INFORMATION_SCHEMA.KEY_COLUMN_USAGE K\n\t\t\t\ton C.TABLE_SCHEMA = K.TABLE_SCHEMA and C.Table_Name = K.Table_Name and C.COLUMN_NAME = K.COLUMN_NAME\n\t\t\t\twhere  C.TABLE_SCHEMA = 'dbo' and C.TABLE_NAME = x.nodeId\n\t\t\t\torder by C.ORDINAL_POSITION ASC\n\t\t\t\tFor JSON Path\n\t\t\t) as Attributes\n\t\tfrom #myEntitiestree x\n\t\twhere nodeIdType = 'USER_TABLE' and x.rootNode = parent.rootNode\n\t\tgroup by nodeId \n\t\tFor JSON Path\n\t) \n\tas DependentTables,\n    (SELECT \n\t\tnodeId as objectName,\n\t\to.type_desc as [type],\n\t\tm.definition as [definition]\n\tFROM #myEntitiestree child\n\tjoin sys.objects o\n\t\ton o.schema_id = schema_id('dbo')\n\t\tand o.name COLLATE DATABASE_DEFAULT = child.nodeId COLLATE DATABASE_DEFAULT \n\t\tand o.type_desc COLLATE DATABASE_DEFAULT =  nodeIdType COLLATE DATABASE_DEFAULT\n\tleft outer join sys.sql_modules m\n\t\ton m.object_id = o.object_id  \n    WHERE \n\t\tparent.rootNode = child.RootNode \n\t\tand nodeIdType in ('VIEW', 'SQL_SCALAR_FUNCTION')\n\t\torder by nodeIdType asc, depth desc\n        FOR JSON PATH\n\t) AS DependentObjects,\n\t(SELECT  \n\t\tstring_agg(convert(nvarchar(max), name + ':' + source_column), ',') \n\t\tFROM   sys.dm_exec_describe_first_result_set (N'SELECT * from dbo.'+ rootNode , null, 1) \n\t\twhere max_length <0\n\t) as MemoFields\nFROM #myEntitiestree parent \ngroup by parent.rootNode\norder by rootNode asc",
												"type": "Expression"
											},
											"queryTimeout": "02:00:00",
											"partitionOption": "None"
										},
										"sink": {
											"type": "ParquetSink",
											"storeSettings": {
												"type": "AzureBlobFSWriteSettings"
											},
											"formatSettings": {
												"type": "ParquetWriteSettings"
											}
										},
										"enableStaging": false
									},
									"inputs": [
										{
											"referenceName": "CDMUtil_AXDB_Dataset",
											"type": "DatasetReference",
											"parameters": {}
										}
									],
									"outputs": [
										{
											"referenceName": "CDMUtil_DependencyFile_Dataset",
											"type": "DatasetReference",
											"parameters": {
												"container": {
													"value": "@pipeline().parameters.container",
													"type": "Expression"
												},
												"folder": {
													"value": "@pipeline().parameters.Environment",
													"type": "Expression"
												},
												"StorageAccount": {
													"value": "@pipeline().parameters.StorageAccount",
													"type": "Expression"
												}
											}
										}
									]
								}
							]
						}
					},
					{
						"name": "SQLTarget_CopyDependency",
						"description": "Copy dependencies file to sql table",
						"type": "IfCondition",
						"dependsOn": [
							{
								"activity": "GetAXDBDependency",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@and(equals(pipeline().parameters.DDLType,'SQLTable'), or(pipeline().parameters.GetDependency, equals(activity('Dependency').output.exists,true)))",
								"type": "Expression"
							},
							"ifTrueActivities": [
								{
									"name": "CopyDependenciesData",
									"type": "Copy",
									"dependsOn": [],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "ParquetSource",
											"storeSettings": {
												"type": "AzureBlobFSReadSettings",
												"recursive": true,
												"enablePartitionDiscovery": false
											}
										},
										"sink": {
											"type": "AzureSqlSink",
											"preCopyScript": {
												"value": "IF  EXISTS (SELECT * FROM sys.objects WHERE object_id = OBJECT_ID(N'[dbo].[_dependencies]') AND type in (N'U'))\n    Drop Table _dependencies\n    \ncreate table _dependencies\n(\n    [EntityName] varchar(500) not null,\n    [DependentTables] varchar(max) Null,\n    [DependentObjects] varchar(max) Null,\n    [MemoFields] varchar(max) Null\n)",
												"type": "Expression"
											},
											"writeBehavior": "insert",
											"sqlWriterUseTableLock": false,
											"disableMetricsCollection": false
										},
										"enableStaging": false,
										"translator": {
											"type": "TabularTranslator",
											"typeConversion": true,
											"typeConversionSettings": {
												"allowDataTruncation": true,
												"treatBooleanAsNumber": false
											}
										}
									},
									"inputs": [
										{
											"referenceName": "CDMUtil_DependencyFile_Dataset",
											"type": "DatasetReference",
											"parameters": {
												"container": {
													"value": "@pipeline().parameters.container",
													"type": "Expression"
												},
												"folder": {
													"value": "@pipeline().parameters.Environment",
													"type": "Expression"
												},
												"StorageAccount": {
													"value": "@pipeline().parameters.StorageAccount",
													"type": "Expression"
												}
											}
										}
									],
									"outputs": [
										{
											"referenceName": "CDMUtil_SQLTable_Dataset",
											"type": "DatasetReference",
											"parameters": {
												"TableName": "_dependencies",
												"DbName": {
													"value": "@pipeline().parameters.DBName",
													"type": "Expression"
												},
												"DBServer": {
													"value": "@pipeline().parameters.DbServer",
													"type": "Expression"
												}
											}
										}
									]
								}
							]
						}
					},
					{
						"name": "CopyMetadata",
						"description": "Recursive copy cdm.json files to metadata.parquet file",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "JsonSource",
								"additionalColumns": [
									{
										"name": "FilePath",
										"value": "$$FILEPATH"
									},
									{
										"name": "Environment",
										"value": {
											"value": "@pipeline().parameters.Environment",
											"type": "Expression"
										}
									}
								],
								"storeSettings": {
									"type": "AzureBlobFSReadSettings",
									"recursive": true,
									"wildcardFolderPath": {
										"value": "@{pipeline().parameters.Environment}/**/",
										"type": "Expression"
									},
									"wildcardFileName": "*.cdm.json",
									"enablePartitionDiscovery": false
								},
								"formatSettings": {
									"type": "JsonReadSettings"
								}
							},
							"sink": {
								"type": "ParquetSink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSettings",
									"copyBehavior": "MergeFiles"
								},
								"formatSettings": {
									"type": "ParquetWriteSettings"
								}
							},
							"enableStaging": false,
							"translator": {
								"type": "TabularTranslator",
								"mappings": [
									{
										"source": {
											"path": "$['definitions']"
										},
										"sink": {
											"name": "definitions",
											"type": "String"
										}
									},
									{
										"source": {
											"path": "$['FilePath']"
										},
										"sink": {
											"name": "FilePath",
											"type": "String"
										}
									},
									{
										"source": {
											"path": "$['Environment']"
										},
										"sink": {
											"name": "Environment",
											"type": "String"
										}
									},
									{
										"source": {
											"path": "$['entities']"
										},
										"sink": {
											"name": "entities",
											"type": "String"
										}
									},
									{
										"source": {
											"path": "$['definitions'][0]['entityName']"
										},
										"sink": {
											"name": "EntityName",
											"type": "String"
										}
									}
								],
								"collectionReference": "",
								"mapComplexValuesToString": true
							}
						},
						"inputs": [
							{
								"referenceName": "CDMUtil_CDM_File_Dataset",
								"type": "DatasetReference",
								"parameters": {
									"Container": {
										"value": "@pipeline().parameters.container",
										"type": "Expression"
									},
									"StorageAccount": {
										"value": "@pipeline().parameters.StorageAccount",
										"type": "Expression"
									}
								}
							}
						],
						"outputs": [
							{
								"referenceName": "CDMUtil_Metadata_File_Dataset",
								"type": "DatasetReference",
								"parameters": {
									"container": {
										"value": "@pipeline().parameters.container",
										"type": "Expression"
									},
									"folder": {
										"value": "@{pipeline().parameters.Environment}",
										"type": "Expression"
									},
									"StorageAccount": {
										"value": "@pipeline().parameters.StorageAccount",
										"type": "Expression"
									}
								}
							}
						]
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"parameters": {
					"StorageAccount": {
						"type": "string",
						"defaultValue": "https://techdeliverydatalake.dfs.core.windows.net/"
					},
					"container": {
						"type": "string",
						"defaultValue": "dynamics365-financeandoperations"
					},
					"Environment": {
						"type": "string",
						"defaultValue": "d365techdelivery-dev.sandbox.operations.dynamics.com"
					},
					"DDLType": {
						"type": "string",
						"defaultValue": "SynapseView"
					},
					"ParserVersion": {
						"type": "string",
						"defaultValue": "2.0"
					},
					"DbName": {
						"type": "string",
						"defaultValue": "fno"
					},
					"Schema": {
						"type": "string",
						"defaultValue": "dbo"
					},
					"ObjectTypes": {
						"type": "string",
						"defaultValue": "Tables,Entities,ChangeFeed"
					},
					"GetDependency": {
						"type": "bool",
						"defaultValue": false
					},
					"EntityListForDependency": {
						"type": "string",
						"defaultValue": "ReplacemeEntity1,Entity2"
					},
					"DbServer": {
						"type": "string",
						"defaultValue": "techdeliverydatalaketesting-ondemand.sql.azuresynapse.net"
					}
				},
				"folder": {
					"name": "CDMUtil"
				},
				"annotations": [],
				"lastPublishTime": "2022-12-12T15:52:28Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/CDMUtil_CDM_File_Dataset')]",
				"[concat(variables('workspaceId'), '/datasets/CDMUtil_Metadata_File_Dataset')]",
				"[concat(variables('workspaceId'), '/linkedServices/Target_Database')]",
				"[concat(variables('workspaceId'), '/datasets/CDMUtil_SQLTable_Dataset')]",
				"[concat(variables('workspaceId'), '/datasets/CDMUtil_DependencyFile_Dataset')]",
				"[concat(variables('workspaceId'), '/datasets/CDMUtil_AXDB_Dataset')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PartitionBySize')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "CSVOrParquet",
						"type": "Switch",
						"dependsOn": [
							{
								"activity": "Get Metadata",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"on": {
								"value": "@toLower(pipeline().parameters.EXT)",
								"type": "Expression"
							},
							"cases": [
								{
									"value": ".parquet",
									"activities": [
										{
											"name": "PartitionBySize_parquet",
											"type": "ExecuteDataFlow",
											"dependsOn": [],
											"policy": {
												"timeout": "7.00:00:00",
												"retry": 0,
												"retryIntervalInSeconds": 30,
												"secureOutput": false,
												"secureInput": false
											},
											"userProperties": [],
											"typeProperties": {
												"dataflow": {
													"referenceName": "PartitionBySize_parquet",
													"type": "DataFlowReference",
													"parameters": {
														"FileName": {
															"value": "'@{pipeline().parameters.FileName}'",
															"type": "Expression"
														},
														"Partition": {
															"value": "@max(div(activity('Get Metadata').output.Size, mul(pipeline().parameters.PartitionSizeMB,1000000)),1)",
															"type": "Expression"
														}
													},
													"datasetParameters": {
														"InputFile": {
															"Container": {
																"value": "@pipeline().parameters.Container",
																"type": "Expression"
															},
															"Folder": {
																"value": "@pipeline().parameters.SourceFolder",
																"type": "Expression"
															},
															"FileName": {
																"value": "@pipeline().parameters.FileName",
																"type": "Expression"
															}
														},
														"PartitionFile": {
															"Container": {
																"value": "@pipeline().parameters.Container",
																"type": "Expression"
															},
															"Folder": {
																"value": "@pipeline().parameters.TargetFolder",
																"type": "Expression"
															}
														}
													}
												},
												"staging": {},
												"compute": {
													"coreCount": 8,
													"computeType": "General"
												},
												"traceLevel": "Fine"
											}
										}
									]
								}
							],
							"defaultActivities": [
								{
									"name": "PartitionBySize",
									"type": "ExecuteDataFlow",
									"dependsOn": [],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataflow": {
											"referenceName": "PartitionBySize_csv",
											"type": "DataFlowReference",
											"parameters": {
												"FileName": {
													"value": "'@{pipeline().parameters.FileName}'",
													"type": "Expression"
												},
												"Partition": {
													"value": "@max(div(activity('Get Metadata').output.Size, mul(pipeline().parameters.PartitionSizeMB,1000000)),1)",
													"type": "Expression"
												}
											},
											"datasetParameters": {
												"InputFile": {
													"Container": {
														"value": "@pipeline().parameters.Container",
														"type": "Expression"
													},
													"Folder": {
														"value": "@pipeline().parameters.SourceFolder",
														"type": "Expression"
													},
													"FileName": {
														"value": "@pipeline().parameters.FileName",
														"type": "Expression"
													}
												},
												"PartitionFile": {
													"Container": {
														"value": "@pipeline().parameters.Container",
														"type": "Expression"
													},
													"Folder": {
														"value": "@pipeline().parameters.TargetFolder",
														"type": "Expression"
													}
												}
											}
										},
										"staging": {},
										"compute": {
											"coreCount": 8,
											"computeType": "General"
										},
										"traceLevel": "Fine"
									}
								}
							]
						}
					},
					{
						"name": "Get Metadata",
						"type": "GetMetadata",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "CSVInputFile1",
								"type": "DatasetReference",
								"parameters": {
									"Container": {
										"value": "@pipeline().parameters.Container",
										"type": "Expression"
									},
									"Folder": {
										"value": "@pipeline().parameters.SourceFolder",
										"type": "Expression"
									},
									"FileName": {
										"value": "@pipeline().parameters.FileName",
										"type": "Expression"
									}
								}
							},
							"fieldList": [
								"size"
							],
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true
							},
							"formatSettings": {
								"type": "DelimitedTextReadSettings"
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"parameters": {
					"Container": {
						"type": "string",
						"defaultValue": "dynamicsax"
					},
					"SourceFolder": {
						"type": "string"
					},
					"FileName": {
						"type": "string"
					},
					"TargetFolder": {
						"type": "string"
					},
					"PartitionSizeMB": {
						"type": "int",
						"defaultValue": 200
					},
					"EXT": {
						"type": "string",
						"defaultValue": ".csv"
					}
				},
				"folder": {
					"name": "PartitionFile"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/CSVInputFile1')]",
				"[concat(variables('workspaceId'), '/dataflows/PartitionBySize_csv')]",
				"[concat(variables('workspaceId'), '/dataflows/PartitionBySize_parquet')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/CDMUtil_AXDB_Dataset')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AXDBConnectionString",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "AzureSqlTable",
				"schema": [],
				"typeProperties": {}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/AXDBConnectionString')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/CDMUtil_CDM_File_Dataset')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Source cdm.json files",
				"linkedServiceName": {
					"referenceName": "Source_DataLake",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"Container": {
						"type": "string",
						"defaultValue": "dynamics365-financeandoperations"
					},
					"StorageAccount": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "Json",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileSystem": {
							"value": "@dataset().Container",
							"type": "Expression"
						}
					}
				},
				"schema": {
					"type": "object",
					"properties": {
						"jsonSchemaSemanticVersion": {
							"type": "string"
						},
						"imports": {
							"type": "array",
							"items": {
								"type": "object",
								"properties": {
									"corpusPath": {
										"type": "string"
									},
									"moniker": {
										"type": "string"
									}
								}
							}
						},
						"definitions": {
							"type": "array",
							"items": {
								"type": "object",
								"properties": {
									"entityName": {
										"type": "string"
									},
									"exhibitsTraits": {
										"type": "array",
										"items": {
											"type": "object",
											"properties": {
												"traitReference": {
													"type": "string"
												},
												"arguments": {
													"type": "array",
													"items": {
														"type": "object",
														"properties": {
															"name": {
																"type": "string"
															},
															"value": {
																"type": "string"
															}
														}
													}
												}
											}
										}
									},
									"attributeContext": {
										"type": "object",
										"properties": {
											"type": {
												"type": "string"
											},
											"name": {
												"type": "string"
											},
											"definition": {
												"type": "string"
											},
											"contents": {
												"type": "array",
												"items": {
													"type": "object",
													"properties": {
														"type": {
															"type": "string"
														},
														"name": {
															"type": "string"
														},
														"parent": {
															"type": "string"
														},
														"definition": {
															"type": "string"
														},
														"contents": {
															"type": "array",
															"items": {
																"type": "string"
															}
														}
													}
												}
											}
										}
									},
									"hasAttributes": {
										"type": "array",
										"items": {
											"type": "object",
											"properties": {
												"name": {
													"type": "string"
												},
												"appliedTraits": {
													"type": "array",
													"items": {
														"type": "string"
													}
												},
												"attributeContext": {
													"type": "string"
												},
												"dataFormat": {
													"type": "string"
												},
												"description": {
													"type": "string"
												}
											}
										}
									},
									"displayName": {
										"type": "string"
									},
									"description": {
										"type": "string"
									},
									"version": {
										"type": "string"
									}
								}
							}
						}
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/Source_DataLake')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/CDMUtil_DependencyFile_Dataset')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Source_DataLake",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"container": {
						"type": "string"
					},
					"folder": {
						"type": "string"
					},
					"StorageAccount": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "dependencies.parquet",
						"folderPath": {
							"value": "@dataset().folder",
							"type": "Expression"
						},
						"fileSystem": {
							"value": "@dataset().container",
							"type": "Expression"
						}
					},
					"compressionCodec": "snappy"
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/Source_DataLake')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/CDMUtil_Metadata_File_Dataset')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Source_DataLake",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"container": {
						"type": "string"
					},
					"folder": {
						"type": "string"
					},
					"StorageAccount": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "metadata.parquet",
						"folderPath": {
							"value": "@dataset().folder",
							"type": "Expression"
						},
						"fileSystem": {
							"value": "@dataset().container",
							"type": "Expression"
						}
					},
					"compressionCodec": "snappy"
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/Source_DataLake')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/CDMUtil_SQLTable_Dataset')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Target_Database",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"DBServer": {
						"type": "string"
					},
					"DbName": {
						"type": "string"
					},
					"TableName": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "AzureSqlTable",
				"schema": [],
				"typeProperties": {
					"schema": "dbo",
					"table": {
						"value": "@dataset().TableName",
						"type": "Expression"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/Target_Database')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/CSVInputFile')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "techdeliverydatalaketesting-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"Container": {
						"type": "string"
					},
					"Folder": {
						"type": "string"
					},
					"FileName": {
						"type": "string"
					}
				},
				"folder": {
					"name": "ADLS/DataFlow"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": {
							"value": "@dataset().FileName",
							"type": "Expression"
						},
						"folderPath": {
							"value": "@dataset().Folder",
							"type": "Expression"
						},
						"fileSystem": {
							"value": "@dataset().Container",
							"type": "Expression"
						}
					},
					"columnDelimiter": ",",
					"escapeChar": "\"",
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/techdeliverydatalaketesting-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/CSVInputFile1')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "techdeliverydatalaketesting-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"Container": {
						"type": "string"
					},
					"Folder": {
						"type": "string"
					},
					"FileName": {
						"type": "string"
					}
				},
				"folder": {
					"name": "ADLS/DataFlow"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": {
							"value": "@dataset().FileName",
							"type": "Expression"
						},
						"folderPath": {
							"value": "@dataset().Folder",
							"type": "Expression"
						},
						"fileSystem": {
							"value": "@dataset().Container",
							"type": "Expression"
						}
					},
					"columnDelimiter": ",",
					"escapeChar": "\"",
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/techdeliverydatalaketesting-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/CSVOutputFile')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "techdeliverydatalaketesting-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"Container": {
						"type": "string"
					},
					"Folder": {
						"type": "string"
					}
				},
				"folder": {
					"name": "ADLS/DataFlow"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": {
							"value": "@dataset().Folder",
							"type": "Expression"
						},
						"fileSystem": {
							"value": "@dataset().Container",
							"type": "Expression"
						}
					},
					"columnDelimiter": ",",
					"escapeChar": "\"",
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/techdeliverydatalaketesting-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/CSVOutputFile1')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "techdeliverydatalaketesting-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"Container": {
						"type": "string"
					},
					"Folder": {
						"type": "string"
					}
				},
				"folder": {
					"name": "ADLS/DataFlow"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": {
							"value": "@dataset().Folder",
							"type": "Expression"
						},
						"fileSystem": {
							"value": "@dataset().Container",
							"type": "Expression"
						}
					},
					"columnDelimiter": ",",
					"escapeChar": "\"",
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/techdeliverydatalaketesting-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ParquetInputFile')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "techdeliverydatalaketesting-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"Container": {
						"type": "string"
					},
					"Folder": {
						"type": "string"
					},
					"FileName": {
						"type": "string"
					}
				},
				"folder": {
					"name": "ADLS/DataFlow"
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": {
							"value": "@dataset().FileName",
							"type": "Expression"
						},
						"folderPath": {
							"value": "@dataset().Folder",
							"type": "Expression"
						},
						"fileSystem": {
							"value": "@dataset().Container",
							"type": "Expression"
						}
					},
					"compressionCodec": "snappy"
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/techdeliverydatalaketesting-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ParquetInputFile1')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "techdeliverydatalaketesting-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"Container": {
						"type": "string"
					},
					"Folder": {
						"type": "string"
					},
					"FileName": {
						"type": "string"
					}
				},
				"folder": {
					"name": "ADLS/DataFlow"
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": {
							"value": "@dataset().FileName",
							"type": "Expression"
						},
						"folderPath": {
							"value": "@dataset().Folder",
							"type": "Expression"
						},
						"fileSystem": {
							"value": "@dataset().Container",
							"type": "Expression"
						}
					},
					"compressionCodec": "snappy"
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/techdeliverydatalaketesting-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ParquetOutputFile')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "techdeliverydatalaketesting-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"Container": {
						"type": "string"
					},
					"Folder": {
						"type": "string"
					}
				},
				"folder": {
					"name": "ADLS/DataFlow"
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": {
							"value": "@dataset().Folder",
							"type": "Expression"
						},
						"fileSystem": {
							"value": "@dataset().Container",
							"type": "Expression"
						}
					},
					"compressionCodec": "snappy"
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/techdeliverydatalaketesting-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ParquetOutputFile1')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "techdeliverydatalaketesting-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"Container": {
						"type": "string"
					},
					"Folder": {
						"type": "string"
					}
				},
				"folder": {
					"name": "ADLS/DataFlow"
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": {
							"value": "@dataset().Folder",
							"type": "Expression"
						},
						"fileSystem": {
							"value": "@dataset().Container",
							"type": "Expression"
						}
					},
					"compressionCodec": "snappy"
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/techdeliverydatalaketesting-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AXDBConnectionString')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureSqlDatabase",
				"typeProperties": {
					"connectionString": "[parameters('AXDBConnectionString_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/FnO_TechDeliverySynapse')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('FnO_TechDeliverySynapse_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Source_DataLake')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"StorageAccount": {
						"type": "String"
					}
				},
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('Source_DataLake_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Target_Database')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"DbServer": {
						"type": "string"
					},
					"DbName": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "AzureSqlDatabase",
				"typeProperties": {
					"connectionString": "[parameters('Target_Database_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Ziegler')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Demo for creating DataFlows in Synapse Studio",
				"annotations": [],
				"type": "PowerBIWorkspace",
				"typeProperties": {
					"workspaceID": "a0f22374-15dc-4c7d-8d98-e1e13691873a",
					"tenantID": "2e14a5b1-fbf8-415b-bc7d-93e20829e510"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/d365techdelivery_CustTable')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "OData",
				"typeProperties": {
					"url": "[parameters('d365techdelivery_CustTable_properties_typeProperties_url')]",
					"authenticationType": "Windows",
					"userName": "[parameters('d365techdelivery_CustTable_properties_typeProperties_userName')]",
					"password": {
						"type": "SecureString",
						"value": "[parameters('d365techdelivery_CustTable_password')]"
					}
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/techdeliverydatalaketesting-WorkspaceDefaultSqlServer')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"DBName": {
						"type": "String"
					}
				},
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('techdeliverydatalaketesting-WorkspaceDefaultSqlServer_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/techdeliverydatalaketesting-WorkspaceDefaultStorage')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('techdeliverydatalaketesting-WorkspaceDefaultStorage_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AutoResolveIntegrationRuntime')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "Managed",
				"typeProperties": {
					"computeProperties": {
						"location": "AutoResolve",
						"dataFlowProperties": {
							"computeType": "General",
							"coreCount": 8,
							"timeToLive": 0
						}
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PartitionBySize_csv')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Partition"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "CSVInputFile1",
								"type": "DatasetReference"
							},
							"name": "InputFile",
							"description": "Load Input file"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "CSVOutputFile1",
								"type": "DatasetReference"
							},
							"name": "PartitionFile",
							"description": "Export data to output file"
						}
					],
					"transformations": [],
					"script": "parameters{\n\tFileName as string,\n\tPartition as integer\n}\nsource(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> InputFile\nInputFile sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tfilePattern:(replace($FileName, '.', '[n].')),\n\tumask: 0022,\n\tpreCommands: [],\n\tpostCommands: [],\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\tpartitionBy('roundRobin', ($Partition))) ~> PartitionFile"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/CSVInputFile1')]",
				"[concat(variables('workspaceId'), '/datasets/CSVOutputFile1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PartitionBySize_parquet')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "Partition"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ParquetInputFile1",
								"type": "DatasetReference"
							},
							"name": "InputFile",
							"description": "Load Input file"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ParquetOutputFile1",
								"type": "DatasetReference"
							},
							"name": "PartitionFile",
							"description": "Export data to output file"
						}
					],
					"transformations": [],
					"script": "parameters{\n\tFileName as string,\n\tPartition as integer\n}\nsource(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false,\n\tformat: 'parquet') ~> InputFile\nInputFile sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tformat: 'parquet',\n\tfilePattern:(replace($FileName, '.', '[n].')),\n\tumask: 0022,\n\tpreCommands: [],\n\tpostCommands: [],\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\tpartitionBy('roundRobin', ($Partition))) ~> PartitionFile"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/ParquetInputFile1')]",
				"[concat(variables('workspaceId'), '/datasets/ParquetOutputFile1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/WorkspaceSystemIdentity')]",
			"type": "Microsoft.Synapse/workspaces/credentials",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "ManagedIdentity",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Adhoc')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "use FnO\nGO\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "fno",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/CopySynapseTableToOnPrem')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "SynapseAdmin"
				},
				"content": {
					"query": "-- Copy data from Syanapse to OnPrem\n-- using a linked server\nCREATE DATABASE FnO_RawOnPrem\nGO\n\nEXEC master.dbo.sp_addlinkedserver\n                        @server = N'SynapseSQL',@srvproduct=N'', @provider=N'MSOLEDBSQL',\n                        @datasrc=N'techdeliverydatalaketesting-ondemand.sql.azuresynapse.net', \n                        @catalog=N'master';\n\nEXEC master.dbo.sp_addlinkedsrvlogin @rmtsrvname=N'SynapseSQL', @useself=N'False',\n                       @locallogin=NULL,\n                       @rmtuser=N'sqladminuser',@rmtpassword='G2qCNH41X4c0oL19O#iB'\nGO\n\nEXEC master.dbo.sp_serveroption @server=N'SynapseSQL', \n                       @optname=N'remote proc transaction promotion', @optvalue=N'false'\nGO\nEXEC master.dbo.sp_serveroption @server=N'SynapseSQL', \n                       @optname=N'rpc', @optvalue=N'true'\nGO\nEXEC master.dbo.sp_serveroption @server=N'SynapseSQL',\n                       @optname=N'rpc out', @optvalue=N'true'\nGO\n\n\nIF  EXISTS (SELECT * FROM FnO_RawOnPrem.sys.objects WHERE object_id = OBJECT_ID(N'CustTable') AND type in (N'U'))\nDROP TABLE CustTable\nGO\n\nselect * into FnO_RawOnPrem.dbo.CustTable from SynapseSQL.FnO.raw.CustTable\nGO\n\nIF  EXISTS (SELECT * FROM FnO_RawOnPrem.sys.objects WHERE object_id = OBJECT_ID(N'CustInvoiceTrans') AND type in (N'U'))\nDROP TABLE FnO_RawOnPrem.dbo.CustInvoiceTrans\nGO\n\nselect SalesId, DefaultDimension, DlvDate, InventQty, InvoiceId \n  into FnO_RawOnPrem.dbo.CustInvoiceTrans \n  from SynapseSQL.FnO.raw.CustInvoiceTrans\nGO",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "FnO",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/KillAll')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "SynapseAdmin"
				},
				"content": {
					"query": "USE [master] \nGO \n\nSELECT 'KILL ' + CAST(session_id AS VARCHAR(10)) AS 'SQL Command'\nFROM sys.dm_exec_sessions\nWHERE is_user_process = 1\nAND database_id = DB_ID('FnO'); --specify database name\n\ndrop database fno",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/_dwPrep')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "VirtualDW"
				},
				"content": {
					"query": "use fno\ngo\n\ncreate schema dw\ngo\n\ncreate external file format ParquetFileFormat with\n  ( format_type = PARQUET,\n    data_compression = 'org.apache.hadoop.io.compress.SnappyCodec' )\ngo\n\ncreate external data source ParquetDataSource\n  with (location = N'https://techdeliverydatalake.dfs.core.windows.net/parquet/'\n       ,credential = [dynamics365_financeandoperations_d365techdelivery_dev_sandbox])\ngo\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "fno",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/_getTablesMetaData')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "SynapseAdmin"
				},
				"content": {
					"query": "declare @tableNames varchar(max) = 'GeneralJournalEntry,GeneralJournalAccountEntry,Ledger,DimensionFinancialTag,DimensionAttributeValueCombination,DirPartyTable,OMOperatingUnit,MainAccount,DimensionAttribute,DimensionAttributeDirCategory';\n\nSelect \nX.Table_Name,\nX.Data_Path,\nX.Manifest_Path,\nX.Manifest_Name,\n'NO_PARTITION' as Partition_Strategy,\n'CREATEDDATETIME' as Partition_DateColumn\nfrom (\nSELECT \n'Tables/' + r.filepath(1) + '/'+ r.filepath(2) + '/' + r.filepath(3) + '/'+ r.filepath(4) + '/' + r.filepath(5)  as [Data_Path],\n'Tables/' + r.filepath(1) + '/'+ r.filepath(2) + '/' + r.filepath(3) + '/'+ r.filepath(4)    as [Manifest_Path],\nr.filepath(4)    as [Manifest_Name],\nr.filepath(5) as [Table_Name]\nFROM OPENROWSET(BULK 'Tables/*/*/*/*/*/index.json', FORMAT = 'CSV', fieldterminator ='0x0b',fieldquote = '0x0b'\n, DATA_SOURCE ='dynamics365_financeandoperations_d365techdelivery_dev_sandbox_EDS') \nwith (firstCol nvarchar(1000)) as r group by r.filepath(1) , r.filepath(2), r.filepath(3) , r.filepath(4), r.filepath(5)\nunion \nSELECT \n'Tables/' + r.filepath(1) + '/'+ r.filepath(2) + '/' + r.filepath(3) + '/'+ r.filepath(4)  as [Data_Path],\n'Tables/' + r.filepath(1) + '/'+ r.filepath(2) + '/' + r.filepath(3)     as [Manifest_Path],\nr.filepath(3)    as [Manifest_Name],\nr.filepath(4) as [Table_Name]\nFROM OPENROWSET(BULK 'Tables/*/*/*/*/index.json', FORMAT = 'CSV', fieldterminator ='0x0b',fieldquote = '0x0b'\n, DATA_SOURCE ='dynamics365_financeandoperations_d365techdelivery_dev_sandbox_EDS') \nwith (firstCol nvarchar(1000)) as r group by r.filepath(1) , r.filepath(2), r.filepath(3) , r.filepath(4)\nunion \nSELECT \n'Tables/' + r.filepath(1) + '/'+ r.filepath(2) + '/' + r.filepath(3)   as [Data_Path],\n r.filepath(3) as [Table_Name],\n'Tables/' + r.filepath(1) + '/'+ r.filepath(2)      as [Manifest_Path],\nr.filepath(2)    as [Manifest_Name]\nFROM OPENROWSET(BULK 'Tables/*/*/*/index.json', FORMAT = 'CSV', fieldterminator ='0x0b',fieldquote = '0x0b'\n, DATA_SOURCE ='dynamics365_financeandoperations_d365techdelivery_dev_sandbox_EDS') \nwith (firstCol nvarchar(1000)) as r group by r.filepath(1) , r.filepath(2), r.filepath(3) \n) X \nwhere X.[Table_Name] not in  (select value from string_split(@tableNames, ',') )\nfor  JSON  PATH",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "fno",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/dBusinessUnit')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "VirtualDW"
				},
				"content": {
					"query": "use FnO\ngo\n\ncreate or alter view raw.vw_dBusinessUnit as \n  select t1.RecId as [Key]\n        ,t1.OMOperatingUnitNumber as BU\n        ,t1.Name as BusinessUnit \n    from raw.DirPartyTable t1 \n   where t1.OMOperatingUnitType = 4 \n     and t1.InstanceRelationType = 8363\ngo\n\n/*\n-- Need to delete the storage in data lake\ndrop external table dw.dBusinessUnit\ngo\n*/\n\ncreate external table dw.dBusinessUnit with (\n    location = 'DataWarehouse/dBusinessUnit'\n   ,data_source = ParquetDataSource\n   ,file_format = ParquetFileFormat\n) as \n    select * from raw.vw_dBusinessUnit\ngo\n\n-- select * from raw.vw_dBusinessUnit\n-- select * from dw.dBusinessUnit",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "fno",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/dCompany')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "VirtualDW/InProgress"
				},
				"content": {
					"query": "use FnO\ngo\n\ncreate or alter view raw.vw_dCompany as \nwith distinctCompanies as (\n  select distinct \n         upper(DataArea) as DataAreaId\n        ,case when DataArea = 'DAT' then 'Do Not Use' else Name end as Name\n    from raw.CompanyInfo\n)\nselect cast(row_number() over(order by DataAreaId) as int) AS [Key]\n      ,DataAreaId\n      ,Name\n  from distinctCompanies\ngo\n\n/*\n-- Need to delete the storage in data lake\ndrop external table dw.dCompany\ngo\n*/\n\ncreate external table dw.dCompany with (\n    location = 'DataWarehouse/dCompany'\n   ,data_source = ParquetDataSource\n   ,file_format = ParquetFileFormat\n) as \n    select * from raw.vw_dCompany\n     order by DataAreaId\ngo\n\n\n-- select * from raw.vw_dCompany\n-- select * from dw.dCompany",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "fno",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/dCostCenter')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "VirtualDW"
				},
				"content": {
					"query": "use FnO\ngo\n\ncreate or alter view raw.vw_dCostCenter as \n  select t1.RecId as [Key]\n        ,t1.OMOperatingUnitNumber as CC\n        ,t1.Name as CostCenter \n    from raw.DirPartyTable t1 \n   where t1.OMOperatingUnitType = 2 \n     and t1.InstanceRelationType = 8363\ngo\n\n/*\n-- Need to also delete the storage in data lake\ndrop external table dw.dCostCenter\ngo\n*/\n\ncreate external table dw.dCostCenter with (\n    location = 'DataWarehouse/dCostCenter'\n   ,data_source = ParquetDataSource\n   ,file_format = ParquetFileFormat\n) as \n    select * from raw.vw_dCostCenter\ngo\n\n-- select * from raw.vw_dCostCenter\n-- select * from dw.dCostCenter",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "fno",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/dCustomer')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "VirtualDW/InProgress"
				},
				"content": {
					"query": "use FnO\ngo\n\ncreate view raw.vw_dCustomer as \n  select ct.RecId as [Key]\n        ,ct.AccountNum as [Account Number]\n        ,dpt.Name as [Customer]\n        -- [Address]\n        ,ct.InvoiceAccount as [Account Number (Invoice)]\n        -- [Invoice Name]\n        -- [Invoice Address]\n        ,ct.PaymTermId as [Payment Terms (Default)]\n        ,ct.CashDisc as [Cash Discount (Default)]\n        ,ct.MaxCredit as [Maximum Credit Limit]\n        ,ct.CreditRating as [Credit Rating]\n        ,ct.Currency as [Currency (Default)]\n        ,ct.CustGroup as [Customer Group Id]\n        ,cg.Name as [Customer Group Name]\n        ,ct.DlvMode as [Delivery Mode (Default)]\n        ,ct.DlvTerm as [Delivery Terms (Default)]\n        ,ct.PaymMode as [Payment Mode (Default)]\n        -- PriceGroup\n        -- SalesDistrictId\n        -- SalesGroup\n        -- SalesPoolId\n        -- SegmentId\n        -- StatisticsGroup\n        -- SubSegmentId\n        -- TaxGroup\n        -- DefaultDimension\n        -- LineOfBusiness\n        -- FirstSalesOrderEntryDate\n        -- LastSalesOrderEntryDate\n    from raw.CustTable ct\n         inner join raw.DirPartyTable dpt on ct.Party = dpt.RecId\n         inner join raw.CustGroup cg on \ngo\n\nselect top 100 * from raw.DirPartyTable\nselect top 1000 * from raw.CustGroup where dataareaid = 'USMF'\nselect top 1000 * from raw.CustTable where dataareaid = 'USMF'",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "fno",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/dDate')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "VirtualDW"
				},
				"content": {
					"query": "use FnO\ngo\n\ncreate view raw.vw_dDate as \nWITH baseDateTable as (\n    SELECT d as [Date]\n        ,DATEPART(DAY, d) as [Day]\n        ,DATEPART(MONTH, d) as [Month]\n        ,CONVERT(DATE, DATEADD(MONTH, DATEDIFF(MONTH, 0, d), 0)) as [FirstOfMonth]\n        ,DATENAME(MONTH, d) as [MonthName]\n        ,DATEPART(WEEK, d) as [Week]\n        ,DATEPART(ISO_WEEK, d) as [ISOweek]\n        ,DATEPART(WEEKDAY, d) as [DayOfWeek]\n        ,DATEPART(QUARTER, d) as [Quarter]\n        ,DATEPART(YEAR, d) as [Year]\n        ,CONVERT(DATE, DATEADD(YEAR,  DATEDIFF(YEAR,  0, d), 0)) as [FirstOfYear]\n        ,CONVERT(CHAR(8), d, 112) as [Style112]\n        ,CONVERT(CHAR(10), d, 101) as [Style101]\n    FROM\n    (\n        SELECT d = DATEADD(DAY, rn -1, '1/1/2010')\n        FROM \n        (\n            SELECT TOP (DATEDIFF(DAY, '1/1/2010', '12/31/2039')) \n            rn = ROW_NUMBER() OVER(ORDER BY (SELECT NULL)) \n            FROM dw.fGeneralLedger AS s1\n            CROSS JOIN dw.fGeneralLedger AS s2\n        ) AS x\n    ) AS y\n)\nSELECT\n  [Date] as [Key], -- Redundant, for symetrical purposes. May cause confusion, can be removed \n  [Date],\n  CONVERT(INT, Style112) as [DateAsInt],\n  CONVERT(TINYINT, [day]) as [Day],\n  CONVERT(TINYINT, [DayOfWeek]) as [Weekday],\n  CONVERT(VARCHAR(10), DATENAME(WEEKDAY, [Date])) as [WeekDayName],\n  CONVERT(TINYINT, ROW_NUMBER() OVER (PARTITION BY FirstOfMonth, [DayOfWeek] ORDER BY [Date])) as [DOWInMonth],\n  CONVERT(SMALLINT, DATEPART(DAYOFYEAR, [Date])) as [DayOfYear],\n  CONVERT(TINYINT, DENSE_RANK() OVER (PARTITION BY [year], [month] ORDER BY [week])) as [WeekOfMonth],\n  CONVERT(TINYINT, [Week]) as [WeekOfYear],\n  CONVERT(TINYINT, ISOWeek) as [ISOWeekOfYear],\n  CONVERT(TINYINT, [month]) as [Month],\n  CONVERT(VARCHAR(10), [MonthName]) as [MonthName],\n  CONVERT(TINYINT, [Quarter]) as Quarter,\n  CONVERT(VARCHAR(6), CASE [quarter] WHEN 1 THEN 'First' WHEN 2 THEN 'Second' WHEN 3 THEN 'Third' WHEN 4 THEN 'Fourth' END) as [QuarterName], \n  [Year],\n  CONVERT(CHAR(7), CONVERT(varchar(2), [Month]) + '/' + CONVERT(varchar(4), [Year])) as [MMYYYY],\n  CONVERT(CHAR(8), CONVERT(varchar(3),[MonthName]) + ' ' + CONVERT(varchar(4), [Year])) as [MonthYear],\n  [FirstOfMonth],\n  MAX([Date]) OVER (PARTITION BY [year], [month]) as [LastDayOfMonth],\n  MIN([Date]) OVER (PARTITION BY [year], [quarter]) as [FirstDayOfQuarter],\n  MAX([Date]) OVER (PARTITION BY [year], [quarter]) as [LastDayOfQuarter],\n  [FirstOfYear] as [FirstDayOfYear],\n  MAX([Date]) OVER (PARTITION BY [year]) as [LastDayOfYear],\n  DATEADD(MONTH, 1, FirstOfMonth) as [FirstDayOfNextMonth],\n  DATEADD(YEAR,  1, FirstOfYear) as FirstDayOfNextYear\nFROM baseDateTable\n\n/*\n-- Need to delete the storage in data lake\ndrop external table dw.dDate\ngo\n*/\n\nSET DATEFIRST 7;\nSET DATEFORMAT mdy;\n\ncreate external table dw.dDate with (\n    location = 'DataWarehouse/dDate'\n   ,data_source = ParquetDataSource\n   ,file_format = ParquetFileFormat\n) as \n    select * from raw.vw_dDate\ngo\n\n-- select * from raw.vw_dDate\n-- select * from dw.dDate",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "fno",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/dDepartment')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "VirtualDW"
				},
				"content": {
					"query": "use FnO\ngo\n\ncreate or alter view raw.vw_dDepartment as \n  select t1.RecId as [Key]\n        ,t1.OMOperatingUnitNumber as Dept\n        ,t1.Name as Department \n    from raw.DirPartyTable t1 \n   where t1.OMOperatingUnitType = 1 \n     and t1.InstanceRelationType = 8363\ngo\n\n/*\n-- Need to delete the storage in data lake\ndrop external table dw.dDepartment\ngo\n*/\n\ncreate external table dw.dDepartment with (\n    location = 'DataWarehouse/dDepartment'\n   ,data_source = ParquetDataSource\n   ,file_format = ParquetFileFormat\n) as \n    select * from raw.vw_dDepartment\ngo\n\n-- select * from raw.vw_dDepartment\n-- select * from dw.dDepartment",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "fno",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/dInventoryDimension')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "VirtualDW/InProgress"
				},
				"content": {
					"query": "use FnO\ngo\n\n-- Need to delete the storage in data lake\ndrop external table dw.dInventoryDimension\ngo\n\ncreate external table dw.dInventoryDimension with (\n    location = 'DataWarehouse/dInventoryDimension'\n   ,data_source = ParquetStorage\n   ,file_format = ParquetFormat\n) as \nwith inventoryDimensions as (\n    select InventDimId\n        ,upper(id.DataAreaId) as DataAreaId\n        ,coalesce(s.SiteId, '') as InventSiteId\n        ,coalesce(s.Name, 'Unknown') as SiteName\n        ,coalesce(l.InventLocationId, '') as InventLocationId\n        ,coalesce(l.Name, 'Unknown') as LocationName\n        ,coalesce(l.InventLocationType, -1) as InventLocationType_Enum\n        ,coalesce(case InventLocationType when 0 then 'Standard' when 1 then 'Quarantine' when 2 then 'Transit' else 'Other' end, 'Unknown') as InventLocationType\n        ,coalesce(w.wMSLocationId, '') as wMSLocationId\n    from raw.InventDim id\n        left outer join raw.InventSite s on s.SiteId = id.InventSiteId and s.DataAreaId = id.DataAreaId\n        left outer join raw.WMSLocation w on w.wMSLocationId = id.wMSLocationId and w.DataAreaId = id.DataAreaId\n        left outer join raw.InventLocation l on l.InventLocationId = id.InventLocationId and l.DataAreaId = id.DataAreaId\n)\nselect cast(row_number() over(order by DataAreaId, InventDimId) as int) AS [Key]\n      ,InventDimId\n      ,DataAreaId\n      ,InventSiteId\n      ,SiteName\n      ,InventLocationId\n      ,LocationName\n      ,InventLocationType\n      ,wMSLocationId\n  from inventoryDimensions\n order by 1\ngo\n\nselect * \n  from dw.dInventoryDimension \n where wMSLocationId <> '' InventLocationType = 'Quarantine'\ngo",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "fno",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/dItem')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "VirtualDW/InProgress"
				},
				"content": {
					"query": "select top 100 ItemId\n              ,upper(DataAreaId) as DataAreaId\n              ,coalesce(Name , 'Unknown') as Name\n              ,CostCenter, CostCenterValue\n  from raw.InventTable it\n    left outer join raw.EcoResProductTranslation n on n.Product = it.Product and LanguageId = 'EN-US'\n    left outer join raw.DimensionAttributeValueSet d on d.RecId = it.DefaultDimension\n\n\nselect * from raw.DimensionAttributeValueSet d inner join raw.InventTable it on it.DefaultDimension = d.RecId\n\nSELECT T1.DISPLAYVALUE AS DISPLAYVALUE, T1.DIMENSIONATTRIBUTEVALUESET AS DEFAULTDIMENSION, T1.PARTITION AS PARTITION, T1.RECID AS RECID, T2.ENTITYINSTANCE AS ENTITYINSTANCE, T2.PARTITION AS PARTITION#2, T3.REPORTCOLUMNNAME AS REPORTCOLUMNNAME, T3.RECID AS DIMENSIONATTRIBUTEID, T3.BACKINGENTITYTYPE AS BACKINGENTITYTYPE, T3.KEYATTRIBUTE AS KEYATTRIBUTE, T3.NAMEATTRIBUTE AS NAMEATTRIBUTE, T3.NAME AS NAME, T3.PARTITION AS PARTITION#3 \nFROM DIMENSIONATTRIBUTEVALUESETITEM T1 \nCROSS JOIN DIMENSIONATTRIBUTEVALUE T2 \nCROSS JOIN DIMENSIONATTRIBUTE T3 \nWHERE((( T1.DIMENSIONATTRIBUTEVALUE  =  T2.RECID)  AND ( T1.PARTITION  =  T2.PARTITION))  AND (( T2.DIMENSIONATTRIBUTE  =  T3.RECID)  AND ( T2.PARTITION  =  T3.PARTITION)))\n\nselect t.name, c.name \n      from sys.all_columns c \n             inner join \n           sys.tables t \n             on t.object_id = c.object_id \n     where t.name = 'DimensionAttributeValueSet'\n\n\nselect distinct CostCenter, CostCenterValue from raw.DimensionAttributeValueSet\nselect * from raw.DimensionFinancialTag\nselect * from raw.FinancialTagCategory\n\nselect\n    gje.AccountingDate as AccountingDate,\n    gje.DocumentDate as DocumentDate,\n    gje.DocumentNumber as DocumentNumber,\n\tgje.JournalNumber as JournalNumber,\n\tdavc.DisplayValue as LedgerDimension,\n\tgjae.MainAccount as MainAccount_FK,\n    davc.CostCenter as CostCenter_FK,\n    davc.Department as Department_FK,\n    davc.BusinessUnit as BusinessUnit_FK,\n    davc.ItemGroup as ItemGroup_FK,\n\tl.RECID as LegalEntity_FK,\n    gjae.ACCOUNTINGCURRENCYAMOUNT as [Amount(AccountingCurrency)],\n    l.ACCOUNTINGCURRENCY as AccountingCurrency,\n\tgjae.REPORTINGCURRENCYAMOUNT as [Amount(ReportingCurrency)],\n\tl.REPORTINGCURRENCY as ReportingCurrency,\n\tgjae.TransactionCurrencyAmount as [Amount(TransactionCurrency)],\n\tgjae.TransactionCurrencyCode as TransactionCurrency,\n\tgje.SubLedgerVoucher as SubLedgerVoucher\nfrom raw.GeneralJournalAccountEntry gjae\njoin raw.GeneralJournalEntry gje on gjae.GeneralJournalEntry = gje.RECID\njoin raw.Ledger l on gje.Ledger = l.RECID\njoin raw.DimensionAttributeValueCombination davc on gjae.LedgerDimension = davc.RECID",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "fno",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/dItemGroup')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "VirtualDW"
				},
				"content": {
					"query": "use FnO\ngo\n\ncreate view raw.vw_dItemGroup as \n  select ig.RecId as [Key]\n        ,ig.ItemGroupId\n\t      ,ig.Name as ItemGroup\n    from raw.InventItemGroup ig\ngo\n\n/*\n-- Need to delete the storage in data lake\ndrop external table dw.dItemGroup\ngo\n*/\n\ncreate external table dw.dItemGroup with (\n    location = 'DataWarehouse/dItemGroup'\n   ,data_source = ParquetDataSource\n   ,file_format = ParquetFileFormat\n) as \n    select * from raw.vw_dItemGroup\ngo\n\n-- select * from raw.vw_dItemGroup\n-- select * from dw.dItemGroup",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "fno",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/dLegalEntity')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "VirtualDW"
				},
				"content": {
					"query": "use FnO\ngo\n\ncreate view raw.vw_dLegalEntity as \n  select l.RecId as [Key]\n        ,upper(dpt.DataArea) as DataAreaId\n        ,dpt.Name as CompanyName   \n    from raw.Ledger l\n         inner join raw.DirPartyTable dpt on l.PrimaryForLegalEntity = dpt.RecId\ngo\n\n/*\n-- Need to delete the storage in data lake\ndrop external table dw.dLegalEntity\ngo\n*/\n\ncreate external table dw.dLegalEntity with (\n    location = 'DataWarehouse/dLegalEntity'\n   ,data_source = ParquetDataSource\n   ,file_format = ParquetFileFormat\n) as \n    select * from raw.vw_dLegalEntity\ngo\n\n-- select * from raw.vw_dLegalEntity\n-- select * from dw.dLegalEntity",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "fno",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/dMainAccount')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "VirtualDW"
				},
				"content": {
					"query": "use FnO\ngo\n\ncreate view raw.vw_dMainAccount as \n  select m.RecId as [Key]\n\t      ,m.MainAccountId as MainAccount\n\t      ,m.Name\n          ,m.Type_$Label as AccountType\n          ,ac.AccountCategory\n          ,ac.AccountType_$Label as AccountCategoryType\n\t      ,l.Name as ChartOfAccountName \n    from raw.MainAccount m\n         inner join raw.LedgerChartOfAccounts l on l.RecId = m.LedgerChartOfAccounts\n         inner join raw.MainAccountCategory ac on ac.AccountCategoryRef = m.AccountCategoryRef\ngo\n\n/*\n-- Need to delete the storage in data lake\ndrop external table dw.dMainAccount\ngo\n*/\n\ncreate external table dw.dMainAccount with (\n    location = 'DataWarehouse/dMainAccount'\n   ,data_source = ParquetDataSource\n   ,file_format = ParquetFileFormat\n) as \n    select * from raw.vw_dMainAccount\ngo\n\n/* Testing\nselect * from raw.MainAccount\nselect * from raw.LedgerChartOfAccounts\nselect * from raw.vw_dMainAccount where ChartOfAccountName = 'Shared'\nselect * from dw.dMainAccount where ChartOfAccountName = 'Shared'\nselect count(*) from dw.dMainAccount\n\n// TODO: BUG FIX REQUIRED\nselect count(*) from raw.MainAccount -- 4751\nselect count(*) from dw.dMainAccount -- 5056\n*/",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "fno",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/fBacklog')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "VirtualDW/InProgress"
				},
				"content": {
					"query": "select top 200 SalesId, DataAreaId, CostPrice, CustAccount, SalesStatus, SalesType, ItemId, ConfirmedDlv, InventDimId, DefaultDimension, LineNum, LineDisc, LinePercent, LineAmount, DlvMode, DlvTerm, QtyOrdered, RemainInventPhysical\n      ShippingDateRequested, ShippingDateConfirmed, SalesCategory, TaxGroup, TaxItemGroup, CreatedDateTime, ModifiedDateTime, * from raw.SalesLine\n\nuse FnO\ngo\n\n-- Need to delete the storage in data lake\ndrop external table dw.fSalesOrder\ngo\n\ncreate external table dw.fSalesOrder with (\n    location = 'DataWarehouse/fSalesOrder'\n   ,data_source = ParquetStorage\n   ,file_format = ParquetFormat\n) as \nwith inventoryDimensions as (\n    select InventDimId\n        ,upper(id.DataAreaId) as DataAreaId\n        ,coalesce(s.SiteId, '') as InventSiteId\n        ,coalesce(s.Name, 'Unknown') as SiteName\n        ,coalesce(l.InventLocationId, '') as InventLocationId\n        ,coalesce(l.Name, 'Unknown') as LocationName\n        ,coalesce(l.InventLocationType, -1) as InventLocationType_Enum\n        ,coalesce(case InventLocationType when 0 then 'Standard' when 1 then 'Quarantine' when 2 then 'Transit' else 'Other' end, 'Unknown') as InventLocationType\n        ,coalesce(w.wMSLocationId, '') as wMSLocationId\n    from raw.InventDim id\n        left outer join raw.InventSite s on s.SiteId = id.InventSiteId and s.DataAreaId = id.DataAreaId\n        left outer join raw.WMSLocation w on w.wMSLocationId = id.wMSLocationId and w.DataAreaId = id.DataAreaId\n        left outer join raw.InventLocation l on l.InventLocationId = id.InventLocationId and l.DataAreaId = id.DataAreaId\n)\nselect cast(row_number() over(order by DataAreaId, InventDimId) as int) AS [Key]\n      ,InventDimId\n      ,DataAreaId\n      ,InventSiteId\n      ,SiteName\n      ,InventLocationId\n      ,LocationName\n      ,InventLocationType\n      ,wMSLocationId\n  from inventoryDimensions\n order by 1\ngo\n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "fno",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/fGeneralLedger')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "VirtualDW"
				},
				"content": {
					"query": "use FnO\ngo\n\ncreate view raw.vw_fGeneralLedger as \n  select gje.AccountingDate as AccountingDate,\n         gje.DocumentDate as DocumentDate,\n         gje.DocumentNumber as DocumentNumber,\n         gje.JournalNumber as JournalNumber,\n         davc.DisplayValue as LedgerDimension,\n         gjae.MainAccount as MainAccount_FK,\n         davc.CostCenter as CostCenter_FK,\n         davc.Department as Department_FK,\n         davc.BusinessUnit as BusinessUnit_FK,\n         davc.ItemGroup as ItemGroup_FK,\n         l.Recid as LegalEntity_FK,\n         gjae.AccountingCurrencyAmount as [Amount(AccountingCurrency)],\n         l.AccountingCurrency as AccountingCurrency,\n         gjae.ReportingCurrencyAmount as [Amount(ReportingCurrency)],\n         l.ReportingCurrency as ReportingCurrency,\n         gjae.TransactionCurrencyAmount as [Amount(TransactionCurrency)],\n         gjae.TransactionCurrencyCode as TransactionCurrency,\n         gje.SubLedgerVoucher as SubLedgerVoucher\n    from raw.GeneralJournalAccountEntry gjae\n         join raw.GeneralJournalEntry gje on gjae.GeneralJournalEntry = gje.RecId\n         join raw.Ledger l on gje.Ledger = l.RecId\n         join raw.DimensionAttributeValueCombination davc on gjae.LedgerDimension = davc.RecId\ngo\n\n/*\n-- Need to delete the storage in data lake\ndrop external table dw.fGeneralLedger\ngo\n*/\n\nselect * from raw.Ledger l\nselect * from dw.dCompany\nselect * from dw.dLegalEntity\n\ncreate external table dw.fGeneralLedger with (\n    location = 'DataWarehouse/fGeneralLedger'\n   ,data_source = ParquetDataSource\n   ,file_format = ParquetFileFormat\n) as \n    select * from raw.vw_fGeneralLedger\ngo\n\n/* Testing\nselect count(*) from raw.vw_fGeneralLedger\nselect count(*) from dw.fGeneralLedger\n\nselect year(AccountingDate) as Year\n      ,count(*) as AccountingEntries\n  from raw.vw_fGeneralLedger -- Using the views\n group by year(AccountingDate)\n order by 1\n\nselect year(AccountingDate) as Year\n      ,count(*) as AccountingEntries\n  from dw.fGeneralLedger\n group by year(AccountingDate)\n order by 1 \n\nselect ma.MainAccount, ma.Name, sum(f.[Amount(AccountingCurrency)]) as Total\n  from dw.fGeneralLedger f \n       inner join dw.dMainAccount ma on ma.[Key] = f.MainAccount_FK\n       inner join dw.dDate d on d.Date = f.AccountingDate\n where ma.ChartOfAccountName = 'Shared'\n   and d.Date = '2016'\n group by ma.MainAccount, ma.Name\n order by 1\n\n-- A query to build the dataflow\n\ncreate view raw.vw_GeneralLedger_Trans as\nselect ma.MainAccount as [Account], ma.Name as [Account Name], ma.AccountType as [Account Type], ma.AccountCategory as [Account Category], ma.AccountCategoryType as [Account Category Type] --, ma.*\n      ,cc.CC as [Cost Center], cc.CostCenter as [Cost Center Name] --, cc.*\n      ,d.Dept as [Department], d.Department as [Department Name] --, d.*\n      ,bu.BU as [Business Unit], bu.BusinessUnit as [Business Unit Name] --, bu.*\n      ,ig.ItemGroupId as [Item Group], ig.ItemGroup as [Item Group Name] -- , ig.*\n      ,le.DataAreaId as [Company], le.CompanyName as [Company Name] --, le.*\n      ,gl.AccountingDate as [Accounting Date], gl.DocumentDate as [Document Date], gl.JournalNumber as [Journal No], gl.LedgerDimension as [Dimension],  gl.[Amount(ReportingCurrency)] as Amount, gl.SubLedgerVoucher as [Sub-Ledger Voucher] -- , gl.*\n  from raw.vw_fGeneralLedger gl\n       inner join raw.vw_dMainAccount ma on ma.[Key] = MainAccount_FK\n       inner join raw.vw_dCostCenter cc on cc.[Key] = CostCenter_FK\n       inner join raw.vw_dDepartment d on d.[Key] = Department_FK\n       inner join raw.vw_dBusinessUnit bu on bu.[Key] = BusinessUnit_FK\n       inner join raw.vw_dItemGroup ig on ig.[Key] = ItemGroup_FK \n       inner join raw.vw_dLegalEntity le on le.[Key] = LegalEntity_FK\n where ma.ChartOfAccountName = 'Shared'\n\n select * from raw.vw_GeneralLedger_Trans\n\ncreate schema dmFin\ndrop view dmFin.GeneralLedger_Trans\ncreate view dmFin.GeneralLedger_Trans as\nselect ma.MainAccount as [Account], ma.Name as [Account Name], ma.AccountType as [Account Type], ma.AccountCategory as [Account Category], ma.AccountCategoryType as [Account Category Type] --, ma.*\n      ,cc.CC as [Cost Center], cc.CostCenter as [Cost Center Name] --, cc.*\n      ,d.Dept as [Department], d.Department as [Department Name] --, d.*\n      ,bu.BU as [Business Unit], bu.BusinessUnit as [Business Unit Name] --, bu.*\n      ,ig.ItemGroupId as [Item Group], ig.ItemGroup as [Item Group Name] -- , ig.*\n      ,le.DataAreaId as [Company], le.CompanyName as [Company Name] --, le.*\n      ,gl.AccountingDate as [Accounting Date], gl.DocumentDate as [Document Date], gl.JournalNumber as [Journal No], gl.LedgerDimension as [Dimension],  gl.[Amount(ReportingCurrency)] as Amount, gl.SubLedgerVoucher as [Sub-Ledger Voucher] -- , gl.*\n  from dw.fGeneralLedger gl\n       inner join dw.dMainAccount ma on ma.[Key] = MainAccount_FK\n       inner join dw.dCostCenter cc on cc.[Key] = CostCenter_FK\n       inner join dw.dDepartment d on d.[Key] = Department_FK\n       inner join dw.dBusinessUnit bu on bu.[Key] = BusinessUnit_FK\n       inner join dw.dItemGroup ig on ig.[Key] = ItemGroup_FK \n       inner join dw.dLegalEntity le on le.[Key] = LegalEntity_FK\n where ma.ChartOfAccountName = 'Shared'\n\n select count(*) from dw.fGeneralLedger\n select count(*) from dmFin.GeneralLedger_Trans\n  */\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "fno",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/fGeneralLedger_BIG')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "VirtualDW"
				},
				"content": {
					"query": "-- For demo purposes\ncreate external table dw.fGeneralLedger_BIG with (\n    location = 'DataWarehouse/fGeneralLedger_BIG'\n   ,data_source = ParquetDataSource\n   ,file_format = ParquetFileFormat\n) as \n    select gl.* \n      from dw.fGeneralLedger gl\n           cross join (select top(10000) row_number() over (order by A.[Key]) as N from dw.dMainAccount A cross join dw.dMainAccount B) cj\ngo\n\n-- NOTE: Too big!\n-- select count(*) from dw.fGeneralLedger_BIG\n\nselect count_big(*) \n  from dw.fGeneralLedger_BIG\n\nselect d.[Year]\n      ,cc.CostCenter\n      ,sum(f.[Amount(AccountingCurrency)])\n  from dw.fGeneralLedger_BIG f\n       inner join dw.dCostCenter cc on cc.[Key] = f.CostCenter_FK\n       inner join dw.dDate d on d.[Date] = f.AccountingDate\n where CostCenter in ('Quality Control', 'Administration', 'Super')\n group by cc.CostCenter, d.[Year] \n order by 1\n\n\nselect ma.MainAccount, ma.Name, sum(f.[Amount(AccountingCurrency)]) as Total\n  from dw.fGeneralLedger_BIG f \n       inner join dw.dMainAccount ma on ma.[Key] = f.MainAccount_FK\n       inner join dw.dDate d on d.Date = f.AccountingDate\n where ma.ChartOfAccountName = 'Shared'\n   and d.Date = '2016'\n group by ma.MainAccount, ma.Name\n order by 1\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "fno",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/fInvoice')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "VirtualDW/InProgress"
				},
				"content": {
					"query": "select top 100 *\n  from raw.CustInvoiceTrans",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/spProfileTable')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "SynapseAdmin"
				},
				"content": {
					"query": "/*\nThis script is given \"As Is\" with no warranties and plenty of caveats. Use at your own risk!\nFor more on data profiling, see Chapter 10 in \"SQL Server 2012 Data Integration Recipes\", Apress, 2012\n*/-----------------------------------------------------------------------\n-- User-defined variables\n-----------------------------------------------------------------------\nUSE fno -- Your database here\nGO\nDECLARE @TABLE_SCHEMA NVARCHAR(128) = 'raw'  -- Your schema here\nDECLARE @TABLE_NAME NVARCHAR(128) = 'InventDim' -- Your table here\nDECLARE @ColumnListIN NVARCHAR(4000) = ''    -- Enter a comma-separated list of specific columns\n                                                     -- to profile, or leave blank for all\nDECLARE @TextCol BIT = 1  -- Analyse all text (char/varchar/nvarchar) data type columns\nDECLARE @NumCol BIT = 1   -- Analyse all numeric data type columns\nDECLARE @DateCol BIT = 1  -- Analyse all date data type data type columns\nDECLARE @LobCol BIT = 1   -- Analyse all VAR(char/nchar/binary) MAX data type columns (potentially time-consuming)\nDECLARE @AdvancedAnalysis BIT = 1 -- Perform advanced analysis (threshold counts/domain analysis) \n                                  --(potentially time-consuming)\nDECLARE @DistinctValuesMinimum INT = 200 -- Minimum number of distinct values to suggest a reference \n                                         -- table and/or perform domain analysis\nDECLARE @BoundaryPercent NUMERIC(3,2) = 0.57 -- Percent of records at upper/lower threshold to suggest\n                                             -- a possible anomaly\nDECLARE @NullBoundaryPercent NUMERIC(5,2) = 90.00 -- Percent of NULLs to suggest a possible anomaly\nDECLARE @DataTypePercentage INT = 2 -- Percentage variance allowed when suggesting another data type \n                                    -- for a column\n-----------------------------------------------------------------------\n-- Process variables\n-----------------------------------------------------------------------\nDECLARE @DATA_TYPE VARCHAR(128) = ''\nDECLARE @FULLSQL VARCHAR(MAX) = ''\nDECLARE @SQLMETADATA VARCHAR(MAX) = ''\nDECLARE @NUMSQL VARCHAR(MAX) = ''\nDECLARE @DATESQL VARCHAR(MAX) = ''\nDECLARE @LOBSQL VARCHAR(MAX) = ''\nDECLARE @COLUMN_NAME VARCHAR(128)\nDECLARE @CHARACTER_MAXIMUM_LENGTH INT\nDECLARE @ROWCOUNT BIGINT = 0\nDECLARE @ColumnList VARCHAR(4000) = ' '\nDECLARE @TableCheck TINYINT\nDECLARE @ColumnCheck SMALLINT\nDECLARE @DataTypeVariance INT\n-----------------------------------------------------------------------\n-- Start the process:\nBEGIN\nTRY\n-- Test that the schema and table exist\nSELECT\n @TableCheck = COUNT (*) \n   FROM INFORMATION_SCHEMA.TABLES \n   WHERE TABLE_SCHEMA = @TABLE_SCHEMA \n   AND TABLE_NAME = @TABLE_NAME\nIF @TableCheck <> 1\n BEGIN\n  RAISERROR ('The table does not exist',16,1)\n  RETURN\n END\n-----------------------------------------------------------------------\n-- Parse list of columns to process / get list of columns according to types required\n-----------------------------------------------------------------------\nIF OBJECT_ID('tempdb..#ColumnList') IS NOT NULL\n DROP TABLE tempdb..#ColumnList;\nCREATE TABLE #ColumnList (COLUMN_NAME VARCHAR(128), DATA_TYPE VARCHAR(128), CHARACTER_MAXIMUM_LENGTH INT) -- Used to hold list of columns to process\nIF @ColumnListIN <> '' -- See if there is a list of columns to process\nBEGIN\n -- Process list\n SET @ColumnList = @ColumnListIN + ','\n DECLARE @CharPosition int\n WHILE CHARINDEX(',', @ColumnList) > 0\n  BEGIN\n   SET @CharPosition = CHARINDEX(',', @ColumnList)\n   INSERT INTO #ColumnList (COLUMN_NAME) VALUES (LTRIM(RTRIM(LEFT(@ColumnList, @CharPosition - 1))))\n   SET @ColumnList = STUFF(@ColumnList, 1, @CharPosition, '')\n  END -- While loop\n-- update with datatype and length\n  UPDATE CL\n   SET CL.CHARACTER_MAXIMUM_LENGTH = ISNULL(ISC.CHARACTER_MAXIMUM_LENGTH,0)\n      ,CL.DATA_TYPE = ISC.DATA_TYPE\n   FROM #ColumnList CL\n   INNER JOIN INFORMATION_SCHEMA.COLUMNS ISC\n     ON CL.COLUMN_NAME = ISC.COLUMN_NAME\n  WHERE ISC.TABLE_NAME = @TABLE_NAME\n  AND ISC.TABLE_SCHEMA = @TABLE_SCHEMA\n END\n-- If test for list of column names\nELSE\n BEGIN\n -- Use all column names, to avoid filtering\n  IF @TextCol = 1\n   BEGIN\n    INSERT INTO #ColumnList (COLUMN_NAME, DATA_TYPE, CHARACTER_MAXIMUM_LENGTH)\n     SELECT COLUMN_NAME, DATA_TYPE, CHARACTER_MAXIMUM_LENGTH FROM INFORMATION_SCHEMA.COLUMNS\n     WHERE DATA_TYPE IN ('varchar', 'nvarchar', 'char', 'nchar', 'binary')\n     AND TABLE_NAME = @TABLE_NAME\n     AND TABLE_SCHEMA = @TABLE_SCHEMA\n     AND CHARACTER_MAXIMUM_LENGTH > 0\n   END\n IF @NumCol = 1\n  BEGIN\n   INSERT INTO #ColumnList (COLUMN_NAME, DATA_TYPE, CHARACTER_MAXIMUM_LENGTH)\n   SELECT COLUMN_NAME, DATA_TYPE, ISNULL(CHARACTER_MAXIMUM_LENGTH,0) FROM INFORMATION_SCHEMA.COLUMNS\n   WHERE DATA_TYPE IN ('numeric', 'int', 'bigint', 'tinyint', 'smallint', 'decimal', 'money', 'smallmoney', 'float','real')\n   AND TABLE_NAME = @TABLE_NAME\n   AND TABLE_SCHEMA = @TABLE_SCHEMA\n  END\n IF @DateCol = 1\n  BEGIN\n   INSERT INTO #ColumnList (COLUMN_NAME, DATA_TYPE, CHARACTER_MAXIMUM_LENGTH)\n   SELECT COLUMN_NAME, DATA_TYPE, ISNULL(CHARACTER_MAXIMUM_LENGTH,0) FROM INFORMATION_SCHEMA.COLUMNS\n   WHERE DATA_TYPE IN ('Date', 'DateTime', 'SmallDateTime', 'DateTime2', 'time')\n   AND TABLE_NAME = @TABLE_NAME\n   AND TABLE_SCHEMA = @TABLE_SCHEMA\n  END\nIF @LOBCol = 1\n BEGIN\n  INSERT INTO #ColumnList (COLUMN_NAME, DATA_TYPE, CHARACTER_MAXIMUM_LENGTH)\n   SELECT COLUMN_NAME, DATA_TYPE, CHARACTER_MAXIMUM_LENGTH FROM INFORMATION_SCHEMA.COLUMNS\n   WHERE DATA_TYPE IN ('varchar', 'nvarchar', 'varbinary', 'xml')\n   AND TABLE_NAME = @TABLE_NAME\n   AND TABLE_SCHEMA = @TABLE_SCHEMA\n   AND CHARACTER_MAXIMUM_LENGTH = -1\n END\nEND\n-- Else test to get all column names\n-----------------------------------------------------------------------\n-- Test that there are columns to analyse\nSELECT @ColumnCheck = COUNT (*) FROM #ColumnList WHERE DATA_TYPE IS NOT NULL\nIF @ColumnCheck = 0\n BEGIN\n  RAISERROR('The columns do not exist in the selected database or no columns are selected',16,1)\n  RETURN\n END\n-----------------------------------------------------------------------\n-- Create Temp table used to hold profiling data\n-----------------------------------------------------------------------\nIF OBJECT_ID('tempdb..#ProfileData') IS NOT NULL\n DROP TABLE tempdb..#ProfileData;\n CREATE TABLE #ProfileData\n (\n  TABLE_SCHEMA NVARCHAR(128),\n  TABLE_NAME NVARCHAR(128),\n  COLUMN_NAME NVARCHAR(128),\n  ColumnDataLength INT,\n  DataType VARCHAR(128),\n  MinDataLength BIGINT,\n  MaxDataLength BIGINT,\n  AvgDataLength BIGINT,\n  MinDate SQL_VARIANT,\n  MaxDate SQL_VARIANT,\n  NoDistinct BIGINT,\n  NoNulls NUMERIC(32,4),\n  NoZeroLength NUMERIC(32,4),\n  PercentageNulls NUMERIC(9,4),\n  PercentageZeroLength NUMERIC(9,4),\n  NoDateWithHourminuteSecond BIGINT NULL,\n  NoDateWithSecond BIGINT NULL,\n  NoIsNumeric BIGINT NULL,\n  NoIsDate BIGINT NULL,\n  NoAtLimit BIGINT NULL,\n  IsFK BIT NULL DEFAULT 0,\n  DataTypeComments NVARCHAR(1500)\n );\n-- Get row count\nDECLARE @ROWCOUNTTEXT NVARCHAR(1000) = ''\nDECLARE @ROWCOUNTPARAM NVARCHAR(50) = ''\nSET @ROWCOUNTTEXT = 'SELECT @ROWCOUNTOUT = COUNT (*) FROM ' + QUOTENAME(@TABLE_SCHEMA) + '.' + QUOTENAME(@TABLE_NAME) + ' WITH (NOLOCK)'\nSET @ROWCOUNTPARAM = '@ROWCOUNTOUT INT OUTPUT'\nEXECUTE sp_executesql @ROWCOUNTTEXT, @ROWCOUNTPARAM, @ROWCOUNTOUT = @ROWCOUNT OUTPUT\n-----------------------------------------------------------------------\n-- Test that there are records to analyse\nIF @ROWCOUNT = 0\n BEGIN\n  RAISERROR('There is no data in the table to analyse',16,1)\n  RETURN\n END\n-----------------------------------------------------------------------\n-- Define the dynamic SQL used for each column to analyse\n-----------------------------------------------------------------------\nSET @SQLMETADATA = 'INSERT INTO #ProfileData (ColumnDataLength,COLUMN_NAME,TABLE_SCHEMA,TABLE_NAME,DataType,MaxDataLength,MinDataLength,AvgDataLength,MaxDate,MinDate,NoDateWithHourminuteSecond,NoDateWithSecond,NoIsNumeric,NoIsDate,NoNulls,NoZeroLength,NoDistinct)'\nDECLARE SQLMETADATA_CUR CURSOR LOCAL FAST_FORWARD FOR \n SELECT COLUMN_NAME, CHARACTER_MAXIMUM_LENGTH, DATA_TYPE FROM #ColumnList\nOPEN SQLMETADATA_CUR \nFETCH NEXT FROM SQLMETADATA_CUR INTO @COLUMN_NAME, @CHARACTER_MAXIMUM_LENGTH, @DATA_TYPE \nWHILE @@FETCH_STATUS = 0 \n BEGIN \n  SET @SQLMETADATA = @SQLMETADATA +'\n  SELECT TOP 100 PERCENT ' + CAST(@CHARACTER_MAXIMUM_LENGTH AS VARCHAR(20)) + ' ,''' + QUOTENAME(@COLUMN_NAME) + '''\n  ,''' + QUOTENAME(@TABLE_SCHEMA) + '''\n  ,''' + QUOTENAME(@TABLE_NAME) + '''\n  ,''' + @DATA_TYPE + ''''\n   + CASE\n      WHEN @DATA_TYPE IN ('varchar', 'nvarchar', 'char', 'nchar') \n   AND @CHARACTER_MAXIMUM_LENGTH >= 0 \n     THEN + '\n  , MAX(LEN(' + QUOTENAME(@COLUMN_NAME) + ')) \n  , MIN(LEN(' + QUOTENAME(@COLUMN_NAME) + ')) \n  , AVG(LEN(' + QUOTENAME(@COLUMN_NAME) + '))\n  ,NULL\n  ,NULL \n  ,NULL \n  ,NULL \n  ,(SELECT COUNT (*) from '\n   + QUOTENAME(@TABLE_SCHEMA) + '.' + QUOTENAME(@TABLE_NAME) + ' WHERE ISNUMERIC(' + QUOTENAME(@COLUMN_NAME) + ') = 1) \n  ,(SELECT COUNT (*) from ' + QUOTENAME(@TABLE_SCHEMA) + '.' + QUOTENAME(@TABLE_NAME) + ' WHERE ISDATE(' + QUOTENAME(@COLUMN_NAME) + ') = 1) '\n  WHEN @DATA_TYPE IN ('numeric', 'int', 'bigint', 'tinyint', 'smallint', 'decimal', 'money', 'smallmoney', 'float','real') THEN + '\n  ,MAX(' + QUOTENAME(@COLUMN_NAME) + ') \n  ,MIN(' + QUOTENAME(@COLUMN_NAME) + ') \n  ,AVG(CAST(' + QUOTENAME(@COLUMN_NAME) + ' AS NUMERIC(36,2)))\n  ,NULL\n  ,NULL \n  ,NULL \n  ,NULL \n  ,NULL \n  ,NULL '\n   WHEN @DATA_TYPE IN ('DateTime', 'SmallDateTime') THEN + '\n  ,NULL \n  ,NULL \n  ,NULL \n  ,MAX(' + QUOTENAME(@COLUMN_NAME) + ') \n  ,MIN(' + QUOTENAME(@COLUMN_NAME) + ')\n  ,(SELECT COUNT (*) from ' \n   + QUOTENAME(@TABLE_SCHEMA) + '.' + QUOTENAME(@TABLE_NAME) + ' WHERE (CONVERT(NUMERIC(20,12), ' + QUOTENAME(@COLUMN_NAME) + ' ) - FLOOR(CONVERT(NUMERIC(20,12), ' + QUOTENAME(@COLUMN_NAME) + ')) <> 0))\n  ,(SELECT COUNT (*) from '\n   + QUOTENAME(@TABLE_SCHEMA) + '.' + QUOTENAME(@TABLE_NAME) + ' WHERE DATEPART(ss,' + QUOTENAME(@COLUMN_NAME) + ') <> 0 OR DATEPART(mcs,' + QUOTENAME(@COLUMN_NAME) + ') <> 0) \n  ,NULL \n  ,NULL '\n    WHEN @DATA_TYPE IN ('DateTime2') THEN + '\n  ,NULL \n  ,NULL \n  ,NULL \n  ,MAX(' + QUOTENAME(@COLUMN_NAME) + ') \n  ,MIN(' + QUOTENAME(@COLUMN_NAME) + ')\n  ,NULL\n  ,NULL\n  ,NULL \n  ,NULL '\n   WHEN @DATA_TYPE IN ('Date') THEN + '\n  ,NULL \n  ,NULL \n  ,NULL \n  ,MAX('\n   + QUOTENAME(@COLUMN_NAME) + ') \n  ,MIN('\n  + QUOTENAME(@COLUMN_NAME) + ')\n  ,NULL \n  ,NLL \n  ,NULL \n  ,NULL '\n   WHEN @DATA_TYPE IN ('xml') THEN + '\n  ,MAX(LEN(CAST(' + QUOTENAME(@COLUMN_NAME) + ' AS NVARCHAR(MAX)))) \n  ,MIN(LEN(CAST(' + QUOTENAME(@COLUMN_NAME) + ' AS NVARCHAR(MAX)))) \n  ,AVG(LEN(CAST(' + QUOTENAME(@COLUMN_NAME) + ' AS NVARCHAR(MAX)))) \n  ,NULL\n  ,NULL \n  ,NULL \n  ,NULL \n  ,NULL \n  ,NULL '\n  WHEN @DATA_TYPE IN ('varbinary','varchar','nvarchar') AND  @CHARACTER_MAXIMUM_LENGTH = -1 THEN + '\n  ,MAX(LEN(' + QUOTENAME(@COLUMN_NAME) + ')) \n  ,MIN(LEN(' + QUOTENAME(@COLUMN_NAME) + ')) \n  ,AVG(LEN(' + QUOTENAME(@COLUMN_NAME) + '))\n  ,NULL\n  ,NULL \n  ,NULL \n  ,NULL \n  ,NULL \n  ,NULL '\n   WHEN @DATA_TYPE IN ('binary') THEN + '\n  ,MAX(LEN(' + QUOTENAME(@COLUMN_NAME) + ')) \n  ,MIN(LEN(' + QUOTENAME(@COLUMN_NAME) + ')) \n  ,AVG(LEN(' + QUOTENAME(@COLUMN_NAME) + '))\n  ,NULL\n  ,NULL \n  ,NULL \n  ,NULL \n  ,NULL \n  ,NULL '\n   WHEN @DATA_TYPE IN ('time') THEN + '\n  ,NULL \n  ,NULL \n  ,NULL \n  ,MAX(' + QUOTENAME(@COLUMN_NAME) + ') \n  ,MIN(' + QUOTENAME(@COLUMN_NAME) + ')\n  ,NULL \n  ,NULL \n  ,NULL \n  ,NULL '\n   ELSE + '\n  ,NULL \n  ,NULL\n  ,NULL\n  ,NULL\n  ,NULL\n  ,NULL \n  ,NULL \n  ,NULL \n  ,NULL '\n  END + '\n  ,(SELECT COUNT(*) FROM ' + QUOTENAME(@TABLE_SCHEMA) + '.' + QUOTENAME(@TABLE_NAME) + ' WHERE ' + QUOTENAME(@COLUMN_NAME) + ' IS NULL)'\n   + CASE\n   WHEN @DATA_TYPE IN ('varchar', 'nvarchar', 'char', 'nchar') THEN + '\n  ,(SELECT COUNT(*) FROM ' + QUOTENAME(@TABLE_SCHEMA) + '.' + QUOTENAME(@TABLE_NAME) +  ' WHERE LEN(LTRIM(RTRIM(' + QUOTENAME(@COLUMN_NAME) + '))) = '''')'\n   ELSE + '\n  ,NULL'\n   END + '\n  ,(SELECT COUNT(DISTINCT ' + QUOTENAME(@COLUMN_NAME) + ') FROM ' + QUOTENAME(@TABLE_SCHEMA) + '.' + QUOTENAME(@TABLE_NAME) + ' WHERE ' + QUOTENAME(@COLUMN_NAME) + ' IS NOT NULL )\n  FROM ' + QUOTENAME(@TABLE_SCHEMA) + '.' + QUOTENAME(@TABLE_NAME) + ' WITH (NOLOCK)\n  UNION'\n FETCH NEXT FROM SQLMETADATA_CUR INTO @COLUMN_NAME, @CHARACTER_MAXIMUM_LENGTH, @DATA_TYPE \nEND \nCLOSE SQLMETADATA_CUR \nDEALLOCATE SQLMETADATA_CUR \nSET @SQLMETADATA = LEFT(@SQLMETADATA, LEN(@SQLMETADATA) -5)\nEXEC (@SQLMETADATA)\n-----------------------------------------------------------------------\n-- Final Calculations\n-----------------------------------------------------------------------\n-- Indicate Foreign Keys\n; WITH FK_CTE (FKColumnName)\nAS\n(\n SELECT\n   DISTINCT CU.COLUMN_NAME\n  FROM INFORMATION_SCHEMA.TABLE_CONSTRAINTS TC\n   INNER JOIN INFORMATION_SCHEMA.CONSTRAINT_COLUMN_USAGE CU\n     ON TC.CONSTRAINT_NAME = CU.CONSTRAINT_NAME \n     AND TC.TABLE_SCHEMA = CU.TABLE_SCHEMA \n     AND TC.TABLE_NAME = CU.TABLE_NAME\n     AND TC.TABLE_SCHEMA = @TABLE_SCHEMA\n     AND TC.TABLE_NAME = @TABLE_NAME\n     AND CONSTRAINT_TYPE = 'FOREIGN KEY'\n)\nUPDATE P\n SET P.IsFK = 1\n FROM #ProfileData P\n  INNER JOIN FK_CTE CTE\n   ON P.COLUMN_NAME = CTE.FKColumnName\n-- Calculate percentages\nUPDATE #ProfileData\n SET PercentageNulls = (NoNulls / @ROWCOUNT) * 100\n    ,PercentageZeroLength = (NoZeroLength / @ROWCOUNT) * 100\n-- Add any comments\n-- Datatype suggestions\n-- First get number of records where a variation could be an anomaly\nSET @DataTypeVariance = ROUND((@ROWCOUNT * @DataTypePercentage) / 100, 0)\nUPDATE #ProfileData\n  SET DataTypeComments = 'Possibly could be one of the DATE types. '\n WHERE NoIsDate BETWEEN (@ROWCOUNT -@DataTypeVariance) AND (@ROWCOUNT + @DataTypeVariance)\n AND DataType IN ('varchar', 'nvarchar', 'char', 'nchar')\nUPDATE #ProfileData\n  SET DataTypeComments = 'Possibly could be one of the NUMERIC types. '\n WHERE NoIsNumeric BETWEEN (@ROWCOUNT -@DataTypeVariance) AND (@ROWCOUNT + @DataTypeVariance)\n AND DataType IN ('varchar', 'nvarchar', 'char', 'nchar')\nUPDATE #ProfileData\n  SET DataTypeComments = 'Possibly could be INT type. '\n WHERE MinDataLength >= -2147483648\n AND MaxDataLength <= 2147483648\n AND DataType IN ('bigint')\n \nUPDATE #ProfileData\n  SET DataTypeComments = 'Possibly could be SMALLINT type. '\n WHERE MinDataLength >= -32768\n AND MaxDataLength <= 32767\n AND DataType IN ('bigint','int')\nUPDATE #ProfileData\n  SET DataTypeComments = 'Possibly could be TINYINT type. '\n WHERE MinDataLength >= 0\n AND MaxDataLength <= 255\n AND DataType IN ('bigint','int','smallint')\nUPDATE #ProfileData\n  SET DataTypeComments = 'Possibly could be SMALLDATE type. '\n WHERE NoDateWithSecond = 0\n AND MinDate >= '19000101'\n AND MaxDate <= '20790606'\n AND DataType IN ('datetime','datetime2')\nUPDATE #ProfileData\n  SET DataTypeComments = 'Possibly could be DATE type (SQL Server 2008 only). '\n WHERE NoDateWithHourminuteSecond = 0\n AND DataType IN ('datetime','datetime2')\nUPDATE #ProfileData\n  SET DataTypeComments = 'Possibly could be DATETIME type. '\n WHERE MinDate >= '17530101'\n AND MaxDate <= '99991231'\n AND DataType IN ('datetime2')\n-- Empty column suggestions\nUPDATE #ProfileData\n  SET DataTypeComments = ISNULL(DataTypeComments,'') + 'Seems empty - is it required? '\n WHERE (PercentageNulls = 100 OR PercentageZeroLength = 100)\n AND IsFK = 0\n-- Null column suggestions\nUPDATE #ProfileData\n  SET DataTypeComments = ISNULL(DataTypeComments,'') + 'There is a large percentage of NULLs - attention may be required. '\n WHERE PercentageNulls >= @NullBoundaryPercent\n-- Distinct value suggestions\nUPDATE #ProfileData\n  SET DataTypeComments = ISNULL(DataTypeComments,'') + 'Few distinct elements - potential for reference/lookup table (contains NULLs).'\n WHERE NoDistinct < @DistinctValuesMinimum\n AND @ROWCOUNT > @DistinctValuesMinimum\n AND IsFK = 0\n AND PercentageNulls <> 100\n AND NoNulls <> 0\n-- FK suggestions\nUPDATE #ProfileData\n  SET DataTypeComments = ISNULL(DataTypeComments,'') + 'Few distinct elements - potential for Foreign Key.'\n WHERE NoDistinct < @DistinctValuesMinimum\n AND @ROWCOUNT > @DistinctValuesMinimum\n AND IsFK = 0\n AND NoNulls = 0\n AND DataType NOT LIKE '%Date%'\n AND DataType <> 'Time'\n-- Filestream suggestions\nUPDATE #ProfileData\n  SET DataTypeComments = 'Possibly a good candidate for FILESTREAM (SQL Server 2008 only).'\n WHERE AvgDataLength >= 1000000\n AND DataType IN ('varbinary')\n AND ColumnDataLength = -1\nUPDATE #ProfileData\n  SET DataTypeComments = 'Possibly not a good candidate for FILESTREAM (SQL Server 2008 only).'\n WHERE AvgDataLength < 1000000\n AND DataType IN ('varbinary')\n AND ColumnDataLength = -1\n-- Sparse Column Suggestions\nIF OBJECT_ID('tempdb..#SparseThresholds') IS NOT NULL\n  DROP TABLE tempdb..#SparseThresholds;\n  CREATE TABLE #SparseThresholds (DataType VARCHAR(128), Threshold NUMERIC(9,4))\n  INSERT INTO #SparseThresholds (DataType, Threshold)\n   VALUES \n    ('tinyint',86),\n    ('smallint',76),    \n    ('int',64),    \n    ('bigint',52),    \n    ('real',64),    \n    ('float',52),    \n    ('money',64),    \n    ('smallmoney',64),    \n    ('smalldatetime',52),    \n    ('datetime',52),    \n    ('uniqueidentifier',43),    \n    ('date',69),    \n    ('datetime2',52),    \n    ('decimal',42),    \n    ('nuumeric',42),    \n    ('char',60),    \n    ('varchar',60),    \n    ('nchar',60),    \n    ('nvarchar',60),    \n    ('binary',60),    \n    ('varbinary',60),    \n    ('xml',60)    \n; WITH Sparse_CTE (COLUMN_NAME, SparseComment)\nAS\n(\nSELECT\n  P.COLUMN_NAME\n ,CASE\n  WHEN P.PercentageNulls >= T.Threshold THEN 'Could benefit from sparse columns. '\n  ELSE ''\n  END AS SparseComment\nFROM #ProfileData P\n INNER JOIN #SparseThresholds T\n  ON P.DataType = T.DataType\n)\nUPDATE PT\n  SET PT.DataTypeComments = \n      CASE WHEN PT.DataTypeComments IS NULL THEN CTE.SparseComment\n           ELSE ISNULL(PT.DataTypeComments,'') + CTE.SparseComment + '. '\n      END\n FROM #ProfileData PT\n  INNER JOIN Sparse_CTE CTE\n   ON PT.COLUMN_NAME = CTE.COLUMN_NAME\n-----------------------------------------------------------------------\n-- Optional advanced analysis\n-----------------------------------------------------------------------\nIF @AdvancedAnalysis = 1\n BEGIN\n-----------------------------------------------------------------------\n-- Data at data boundaries\n-----------------------------------------------------------------------\n  IF OBJECT_ID('tempdb..#LimitTest') IS NOT NULL\n    DROP TABLE tempdb..#LimitTest;\n    CREATE TABLE #LimitTest (COLUMN_NAME VARCHAR(128), NoAtLimit BIGINT);\n    DECLARE @advancedtestSQL VARCHAR(MAX) = 'INSERT INTO #LimitTest (COLUMN_NAME, NoAtLimit)' + CHAR(13)\n    SELECT @advancedtestSQL = @advancedtestSQL + 'SELECT '''+ COLUMN_NAME + ''', COUNT('+ COLUMN_NAME + ') FROM ' + @TABLE_SCHEMA + '.' + @TABLE_NAME + \n     CASE\n       WHEN DataType IN ('numeric', 'int', 'bigint', 'tinyint', 'smallint', 'decimal', 'money', 'smallmoney', 'float','real') THEN ' WHERE '+ COLUMN_NAME + ' = ' + CAST(ISNULL(MaxDataLength,0) AS VARCHAR(40)) + ' OR '+ COLUMN_NAME + ' = ' + CAST(ISNULL(MinDataLength,0) AS VARCHAR(40)) + CHAR(13) + ' UNION' + CHAR(13)\n       ELSE ' WHERE LEN('+ COLUMN_NAME + ') = ' + CAST(ISNULL(MaxDataLength,0) AS VARCHAR(40)) + ' OR LEN('+ COLUMN_NAME + ') = ' + CAST(ISNULL(MinDataLength,0) AS VARCHAR(40)) + CHAR(13) + ' UNION' + CHAR(13)\n     END\n    FROM #ProfileData \n    WHERE DataType IN ('numeric', 'int', 'bigint', 'tinyint', 'smallint', 'decimal', 'money', 'smallmoney', 'float','real','varchar', 'nvarchar', 'char', 'nchar', 'binary')\n    SET @advancedtestSQL = LEFT(@advancedtestSQL,LEN(@advancedtestSQL) -6) \n    EXEC (@advancedtestSQL)\n    UPDATE M\n      SET M.NoAtLimit = T.NoAtLimit\n         ,M.DataTypeComments = \n           CASE\n             WHEN CAST(T.NoAtLimit AS NUMERIC(36,2)) / CAST(@ROWCOUNT AS NUMERIC(36,2)) >= @BoundaryPercent THEN ISNULL(M.DataTypeComments,'') + 'Large numbers of data elements at the max/minvalues. '\n             ELSE M.DataTypeComments\n           END\n    FROM #ProfileData M\n     INNER JOIN #LimitTest T\n      ON M.COLUMN_NAME = T.COLUMN_NAME\n   -----------------------------------------------------------------------\n   -- Domain analysis\n   -----------------------------------------------------------------------\n   IF OBJECT_ID('tempdb..#DomainAnalysis') IS NOT NULL\n     DROP TABLE tempdb..#DomainAnalysis;\n   CREATE TABLE #DomainAnalysis\n   (\n    DomainName NVARCHAR(128)\n   ,DomainElement NVARCHAR(4000)\n   ,DomainCounter BIGINT\n   ,DomainPercent NUMERIC(7,4)\n   );\n   DECLARE @DOMAINSQL VARCHAR(MAX) = 'INSERT INTO #DomainAnalysis (DomainName, DomainElement, DomainCounter) '\n   DECLARE SQLDOMAIN_CUR CURSOR LOCAL FAST_FORWARD FOR \n     SELECT COLUMN_NAME, DataType \n  FROM #ProfileData \n   WHERE NoDistinct < @DistinctValuesMinimum\n   OPEN SQLDOMAIN_CUR \n   FETCH NEXT FROM SQLDOMAIN_CUR INTO @COLUMN_NAME, @DATA_TYPE \n   WHILE @@FETCH_STATUS = 0 \n    BEGIN \n     SET @DOMAINSQL = @DOMAINSQL + 'SELECT ''' + @COLUMN_NAME + ''' AS DomainName, CAST( '+ @COLUMN_NAME + ' AS VARCHAR(4000)) AS DomainElement, COUNT(ISNULL(CAST(' + @COLUMN_NAME + ' AS NVARCHAR(MAX)),'''')) AS DomainCounter FROM ' + @TABLE_SCHEMA + '.' + @TABLE_NAME + ' GROUP BY ' + @COLUMN_NAME + ''\n     + ' UNION '\n     FETCH NEXT FROM SQLDOMAIN_CUR INTO @COLUMN_NAME, @DATA_TYPE \n   END \n  CLOSE SQLDOMAIN_CUR \n  DEALLOCATE SQLDOMAIN_CUR \n  SET @DOMAINSQL = LEFT(@DOMAINSQL, LEN(@DOMAINSQL) -5) + ' ORDER BY DomainName ASC, DomainCounter DESC '\n   EXEC (@DOMAINSQL)\n   -- Now calculate percentages (this appraoch is faster than doing it when performing the domain analysis)\n   ; WITH DomainCounter_CTE (DomainName, DomainCounterTotal)\n   AS\n  (\n   SELECT DomainName, SUM(ISNULL(DomainCounter,0)) AS DomainCounterTotal\n    FROM #DomainAnalysis \n    GROUP BY DomainName\n  )\n  UPDATE D\n    SET D.DomainPercent = (CAST(D.DomainCounter AS NUMERIC(36,4)) / CAST(CTE.DomainCounterTotal AS NUMERIC(36,4))) * 100\n   FROM #DomainAnalysis D\n    INNER JOIN DomainCounter_CTE CTE\n     ON D.DomainName = CTE.DomainName\n   WHERE D.DomainCounter <> 0\n END\n-- Advanced analysis\n-----------------------------------------------------------------------\n-- Output results from the profile and domain data tables\n-----------------------------------------------------------------------\nselect\n   *\n from #ProfileData\nIF @AdvancedAnalysis = 1\n BEGIN\n  select\n    *\n   from #DomainAnalysis\n END\nEND TRY\nBEGIN CATCH\n SELECT\n  ERROR_NUMBER() AS ErrorNumber\n ,ERROR_SEVERITY() AS ErrorSeverity\n ,ERROR_STATE() AS ErrorState\n ,ERROR_PROCEDURE() AS ErrorProcedure\n ,ERROR_LINE() AS ErrorLine\n ,ERROR_MESSAGE() AS ErrorMessage;\n \nEND CATCH",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "fno",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		}
	]
}